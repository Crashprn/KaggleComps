{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import EarlyStopping, Checkpoint, LRScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from models import FFNeuralNetwork, LSTMNeuralNetwork, LSTMDataset\n",
    "from utilities import create_scaled_data_by_col, rmsle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "store_nbr",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "family",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "onpromotion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "city",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "state",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store_type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "oil",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "h_type_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_description_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_transferred_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_type_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_description_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_transferred_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_of_week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dow_avg_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_1_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_3_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_7_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_avg_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_1_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_3_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_7_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_1_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_7_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_14_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_1_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_7_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_14_transactions",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4a2cfee4-d8d0-49e3-9943-fa0e563776b7",
       "rows": [
        [
         "0",
         "2013-02-01 00:00:00",
         "1",
         "0",
         "3.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "2013-02-01 00:00:00",
         "1",
         "1",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "2013-02-01 00:00:00",
         "1",
         "2",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "2013-02-01 00:00:00",
         "1",
         "3",
         "941.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "2013-02-01 00:00:00",
         "1",
         "4",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 35,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>store_type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>oil</th>\n",
       "      <th>...</th>\n",
       "      <th>dow_avg_transactions</th>\n",
       "      <th>dow_rolling_1_transactions</th>\n",
       "      <th>dow_rolling_3_transactions</th>\n",
       "      <th>dow_rolling_7_transactions</th>\n",
       "      <th>prev_1_sales</th>\n",
       "      <th>prev_7_sales</th>\n",
       "      <th>prev_14_sales</th>\n",
       "      <th>prev_1_transactions</th>\n",
       "      <th>prev_7_transactions</th>\n",
       "      <th>prev_14_transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>941.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  family  sales  onpromotion  city  state  store_type  \\\n",
       "0 2013-02-01          1       0    3.0            0     0      0           0   \n",
       "1 2013-02-01          1       1    0.0            0     0      0           0   \n",
       "2 2013-02-01          1       2    0.0            0     0      0           0   \n",
       "3 2013-02-01          1       3  941.0            0     0      0           0   \n",
       "4 2013-02-01          1       4    0.0            0     0      0           0   \n",
       "\n",
       "   cluster    oil  ...  dow_avg_transactions  dow_rolling_1_transactions  \\\n",
       "0       13  97.46  ...                   0.0                         0.0   \n",
       "1       13  97.46  ...                   0.0                         0.0   \n",
       "2       13  97.46  ...                   0.0                         0.0   \n",
       "3       13  97.46  ...                   0.0                         0.0   \n",
       "4       13  97.46  ...                   0.0                         0.0   \n",
       "\n",
       "   dow_rolling_3_transactions  dow_rolling_7_transactions  prev_1_sales  \\\n",
       "0                         0.0                         0.0           0.0   \n",
       "1                         0.0                         0.0           0.0   \n",
       "2                         0.0                         0.0           0.0   \n",
       "3                         0.0                         0.0           0.0   \n",
       "4                         0.0                         0.0           0.0   \n",
       "\n",
       "   prev_7_sales  prev_14_sales  prev_1_transactions  prev_7_transactions  \\\n",
       "0           0.0            0.0                  0.0                  0.0   \n",
       "1           0.0            0.0                  0.0                  0.0   \n",
       "2           0.0            0.0                  0.0                  0.0   \n",
       "3           0.0            0.0                  0.0                  0.0   \n",
       "4           0.0            0.0                  0.0                  0.0   \n",
       "\n",
       "   prev_14_transactions  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = 'data/'\n",
    "df = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(by=['date', 'store_nbr'])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['store_nbr', 'city', 'state', 'store_type', 'cluster', 'h_type_nat', 'h_description_nat', 'h_transferred_nat', 'h_type_loc', 'h_description_loc', 'h_transferred_loc', 'month', 'day', 'day_of_week']\n",
      "Index(['date', 'store_nbr', 'family', 'sales', 'onpromotion', 'city', 'state',\n",
      "       'store_type', 'cluster', 'oil', 'h_type_nat', 'h_description_nat',\n",
      "       'h_transferred_nat', 'h_type_loc', 'h_description_loc',\n",
      "       'h_transferred_loc', 'transactions', 'year', 'month', 'day',\n",
      "       'day_of_week', 'dow_avg_sales', 'dow_rolling_1_sales',\n",
      "       'dow_rolling_3_sales', 'dow_rolling_7_sales', 'dow_avg_transactions',\n",
      "       'dow_rolling_1_transactions', 'dow_rolling_3_transactions',\n",
      "       'dow_rolling_7_transactions', 'prev_1_sales', 'prev_7_sales',\n",
      "       'prev_14_sales', 'prev_1_transactions', 'prev_7_transactions',\n",
      "       'prev_14_transactions'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "min_max_cols = ['store_nbr', 'city', 'state', 'store_type', 'cluster', 'h_type_nat', 'h_description_nat', 'h_transferred_nat', 'h_type_loc', 'h_description_loc', 'h_transferred_loc', 'month', 'day', 'day_of_week']\n",
    "normalize_cols = ['onpromotion', 'oil', 'dow_avg_sales', 'dow_rolling_1_sales', 'dow_rolling_3_sales', 'prev_1_sales', 'prev_7_sales', 'prev_14_sales', 'dow_avg_transactions', 'dow_rolling_1_transactions', 'dow_rolling_3_transactions', 'prev_1_transactions', 'prev_7_transactions', 'prev_14_transactions']\n",
    "x_cols = min_max_cols + normalize_cols\n",
    "y_cols = ['sales']\n",
    "split_col = 'family'\n",
    "\n",
    "print(min_max_cols)\n",
    "print(df.columns)\n",
    "\n",
    "final_run = False\n",
    "\n",
    "if final_run:\n",
    "    train_df = df\n",
    "else:\n",
    "    rows_before = (df['date'] < '2017-07-27')\n",
    "    rows_after = ~rows_before\n",
    "\n",
    "    print('rows_before', rows_before.sum())\n",
    "    print('rows_after', rows_after.sum())\n",
    "    print('rows_total', len(df))\n",
    "\n",
    "    train_df = df[rows_before]\n",
    "    val_df = df[rows_after]\n",
    "\n",
    "train_df_by_cluster = {}\n",
    "scaler_x_by_cluster = {}\n",
    "scaler_y_by_cluster = {}\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    cluster_df, cluster_min_max_scaler, cluster_normalize_scaler, cluster_y_scaler = create_scaled_data_by_col(train_df, min_max_cols, normalize_cols, y_cols, split_col, cluster)\n",
    "    train_df_by_cluster[cluster] = cluster_df\n",
    "    scaler_x_by_cluster[cluster] = (cluster_min_max_scaler, cluster_normalize_scaler)\n",
    "    scaler_y_by_cluster[cluster] = cluster_y_scaler\n",
    "\n",
    "if not final_run:\n",
    "    val_df_by_cluster = {}\n",
    "\n",
    "    for cluster in df[split_col].unique():\n",
    "        val_cluster_min_max_scaler, val_cluster_normalize_scaler = scaler_x_by_cluster[cluster]\n",
    "        val_cluster_y_scaler = scaler_y_by_cluster[cluster]\n",
    "\n",
    "        val_cluster_df = val_df[val_df[split_col] == cluster]\n",
    "        val_cluster_df = val_cluster_df.drop(columns=split_col)\n",
    "\n",
    "        val_cluster_x_min_max = val_cluster_df[min_max_cols].values.astype(np.float32)\n",
    "        val_cluster_x_normalize = val_cluster_df[normalize_cols].values.astype(np.float32)\n",
    "        val_cluster_y = val_cluster_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "\n",
    "        val_cluster_x_min_max = val_cluster_min_max_scaler.transform(val_cluster_x_min_max)\n",
    "        val_cluster_x_normalize = val_cluster_normalize_scaler.transform(val_cluster_x_normalize)\n",
    "        val_cluster_y = val_cluster_y_scaler.transform(val_cluster_y)\n",
    "\n",
    "        val_cluster_df[min_max_cols] = val_cluster_x_min_max\n",
    "        val_cluster_df[normalize_cols] = val_cluster_x_normalize\n",
    "        val_cluster_df[y_cols] = val_cluster_y\n",
    "\n",
    "        val_df_by_cluster[cluster] = val_cluster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_by_cluster = {}\n",
    "train_params = {\n",
    "                \"criterion\": nn.L1Loss,\n",
    "                \"optimizer\": torch.optim.AdamW,\n",
    "                \"optimizer__weight_decay\": 1e-8,\n",
    "                #'train_split' : None,\n",
    "                #\"train_split\": predefined_split(Dataset(val_x, val_y)),\n",
    "                \"lr\": 0.001,\n",
    "                \"batch_size\": 128,\n",
    "                \"max_epochs\": 1000,\n",
    "                \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                \"iterator_train__shuffle\": False,\n",
    "                \"iterator_train__num_workers\": 2,\n",
    "                \"iterator_train__pin_memory\": True,\n",
    "                \"iterator_valid__shuffle\": False,\n",
    "                \"iterator_valid__num_workers\": 2,\n",
    "                \"iterator_valid__pin_memory\": True,\n",
    "                \"verbose\": 2,\n",
    "        }\n",
    "\n",
    "net_params = {\n",
    "    'input_dim': len(x_cols),\n",
    "    'out_dim': 1,\n",
    "    'hidden_dim': 200,\n",
    "    'num_hidden_layers': 6,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key 'valid_loss' was not found in history.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m train_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m     19\u001b[0m net \u001b[38;5;241m=\u001b[39m NeuralNetRegressor(FFNeuralNetwork(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnet_params), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrain_params)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m net_by_cluster[cluster] \u001b[38;5;241m=\u001b[39m net\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/skorch/regressor.py:82\u001b[0m, in \u001b[0;36mNeuralNetRegressor.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# this is actually a pylint bug:\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNeuralNetRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/skorch/net.py:1319\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized_:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/skorch/net.py:1278\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_train_begin\u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/skorch/net.py:1196\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single_epoch(iterator_train, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1191\u001b[0m                           step_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single_epoch(iterator_valid, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1194\u001b[0m                           step_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m-> 1196\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotify\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_epoch_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mon_epoch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/skorch/net.py:386\u001b[0m, in \u001b[0;36mNeuralNet.notify\u001b[0;34m(self, method_name, **cb_kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_name)(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcb_kwargs)\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks_:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcb_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/skorch/callbacks/training.py:429\u001b[0m, in \u001b[0;36mEarlyStopping.on_epoch_end\u001b[0;34m(self, net, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, net, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 429\u001b[0m     current_score \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonitor\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_score_improved(current_score):\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmisses_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/skorch/history.py:291\u001b[0m, in \u001b[0;36mHistory.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    287\u001b[0m     items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(_not_none, items))\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (k_e \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatches\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i_b \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# none of the epochs matched\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(keyerror_msg\u001b[38;5;241m.\u001b[39mformat(key))\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(i_b, \u001b[38;5;28mslice\u001b[39m)\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m k_b \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(batches \u001b[38;5;28;01mfor\u001b[39;00m batches \u001b[38;5;129;01min\u001b[39;00m items)\n\u001b[1;32m    297\u001b[0m ):\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# none of the batches matched\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(keyerror_msg\u001b[38;5;241m.\u001b[39mformat(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'valid_loss' was not found in history.\""
     ]
    }
   ],
   "source": [
    "for cluster in df[split_col].unique():\n",
    "    train_df = train_df_by_cluster[cluster]\n",
    "    train_x = train_df[x_cols].values.astype(np.float32)\n",
    "    train_y = train_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "\n",
    "    if not final_run:\n",
    "        val_df = val_df_by_cluster[cluster]\n",
    "        train_params['train_split'] = predefined_split(Dataset(val_df[x_cols].values.astype(np.float32), val_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)))\n",
    "    else:\n",
    "        train_params['train_split'] = None\n",
    "\n",
    "    callbacks = [EarlyStopping(patience=15, threshold=0.001, threshold_mode='abs', monitor='valid_loss', lower_is_better=True),\n",
    "            Checkpoint(monitor='valid_loss_best', f_params=f'sales_forecaster_{cluster}.pt', dirname='models/'),\n",
    "            LRScheduler(policy=ReduceLROnPlateau, monitor='valid_loss', factor=0.5, patience=5, threshold=0.001, threshold_mode='abs', mode='min', verbose=True)\n",
    "            ]\n",
    "\n",
    "    train_params['callbacks'] = callbacks\n",
    "\n",
    "    net = NeuralNetRegressor(FFNeuralNetwork(**net_params), **train_params)\n",
    "\n",
    "    net.fit(train_x, train_y)\n",
    "    net_by_cluster[cluster] = net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Nets from Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in df[split_col].unique():\n",
    "    net = NeuralNetRegressor(FFNeuralNetwork(**net_params), **train_params)\n",
    "    net.initialize()\n",
    "    net.load_params(f_params=f'models/sales_forecaster_{cluster}.pt')\n",
    "    net_by_cluster[cluster] = net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "endogenous_cols = [\n",
    "        'sales', 'onpromotion', 'oil', \n",
    "       'dow_avg_sales', 'dow_rolling_3_sales', 'dow_rolling_7_sales',\n",
    "       'dow_avg_transactions', 'dow_rolling_3_transactions',\n",
    "       'dow_rolling_7_transactions', 'rolling_7_sales', 'rolling_14_sales',\n",
    "       'rolling_7_transactions', 'rolling_14_transactions']\n",
    "\n",
    "exogenous_cols = [\n",
    "    'h_type_nat', 'h_description_nat', 'h_transferred_nat', 'h_type_loc',\n",
    "    'h_description_loc', 'h_transferred_loc', 'month', 'day', 'day_of_week', 'store_nbr'\n",
    "    ]\n",
    "\n",
    "out_cols = ['sales']\n",
    "\n",
    "\n",
    "lstm_net_by_cluster = {}\n",
    "lstm_net_params = {\n",
    "    'input_dim': 512,\n",
    "    'endogenous_dim': len(endogenous_cols)*54,\n",
    "    'endogenous_len': 5,\n",
    "    'exogenous_dim': len(exogenous_cols),\n",
    "    'hidden_dim': 1024,\n",
    "    'out_dim': 54,\n",
    "    'out_seq_len': 15,\n",
    "    'num_layers': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, RMSLE: 0.59281 L1: 2621.91406\n",
      "Epoch 2/1000, RMSLE: 0.59805 L1: 2591.96606\n",
      "Epoch 3/1000, RMSLE: 0.61355 L1: 2627.24707\n",
      "Epoch 4/1000, RMSLE: 0.61980 L1: 2648.24902\n",
      "Epoch 5/1000, RMSLE: 0.63566 L1: 2669.86035\n",
      "Epoch 6/1000, RMSLE: 0.64438 L1: 2688.27637\n",
      "Epoch 7/1000, RMSLE: 0.66854 L1: 2746.78809\n",
      "Epoch 8/1000, RMSLE: 0.68094 L1: 2764.41455\n",
      "Epoch 9/1000, RMSLE: 0.69042 L1: 2781.10596\n",
      "Epoch 10/1000, RMSLE: 0.69891 L1: 2787.39185\n",
      "Epoch 11/1000, RMSLE: 0.69744 L1: 2791.86279\n",
      "Epoch 12/1000, RMSLE: 0.69394 L1: 2789.51074\n",
      "Epoch 13/1000, RMSLE: 0.70647 L1: 2797.06030\n",
      "Epoch 14/1000, RMSLE: 0.69428 L1: 2787.90845\n",
      "Epoch 15/1000, RMSLE: 0.70769 L1: 2804.49365\n",
      "Epoch 16/1000, RMSLE: 0.69218 L1: 2788.97607\n",
      "Epoch 17/1000, RMSLE: 0.71373 L1: 2809.92358\n",
      "Epoch 18/1000, RMSLE: 0.68829 L1: 2788.63428\n",
      "Epoch 19/1000, RMSLE: 0.71235 L1: 2810.70557\n",
      "Epoch 20/1000, RMSLE: 0.68650 L1: 2790.86255\n",
      "Epoch 21/1000, RMSLE: 0.71120 L1: 2808.48950\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 1000\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    train_df = train_df_by_cluster[cluster]\n",
    "    train_dataset = LSTMDataset(train_df, 5, 15, 'date', endogenous_cols, exogenous_cols, out_cols, 'store_nbr')\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=30, shuffle=False)\n",
    "\n",
    "    scaler_y = scaler_y_by_cluster[cluster]\n",
    "\n",
    "    val_df = val_df_by_cluster[cluster]\n",
    "    val_dataset = LSTMDataset(val_df, 5, 15, 'date', endogenous_cols, exogenous_cols, out_cols, 'store_nbr')\n",
    "\n",
    "    model = LSTMNeuralNetwork(**lstm_net_params)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-8)\n",
    "    criterion = nn.L1Loss()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    model.zero_grad()\n",
    "\n",
    "    val = val_dataset[0]\n",
    "    val_endog = torch.tensor(val['endog']).unsqueeze(0).to(device).to(torch.float32)\n",
    "    val_exog = torch.tensor(val['exog']).unsqueeze(0).to(device).to(torch.float32)\n",
    "    val_y = scaler_y.inverse_transform(val['label'].reshape(-1,1).astype(np.float32))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for sample in train_loader:\n",
    "            endog = sample['endog'].to(device).to(torch.float32)\n",
    "            exog = sample['exog'].to(device).to(torch.float32)\n",
    "            y = sample['label'].to(device).to(torch.float32)\n",
    "            optim.zero_grad()\n",
    "            output = model((endog, exog))\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_pred = model((val_endog, val_exog))\n",
    "            val_pred = val_pred.view(-1,1).cpu().detach().numpy()\n",
    "            val_pred = scaler_y.inverse_transform(val_pred)\n",
    "\n",
    "            val_loss1 = rmsle(val_y, val_pred.clip(0))\n",
    "            val_loss2 = np.abs(val_y - val_pred).sum()\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, RMSLE: {val_loss1.item():6.5f} L1: {val_loss2:6.5f}')\n",
    "            model.train()\n",
    "\n",
    "\n",
    "    lstm_net_by_cluster[cluster] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "cluster_rfs = {}\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    train_df = train_df_by_cluster[cluster]\n",
    "\n",
    "    train_x = train_df[x_cols].values.astype(np.float32)\n",
    "    train_y = train_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=4)\n",
    "    rf.fit(train_x, train_y.squeeze())\n",
    "\n",
    "    cluster_rfs[cluster] = rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "cluster_xgb = {}\n",
    "for cluster in df[split_col].unique():\n",
    "    train_x = train_x_by_cluster[cluster]\n",
    "    train_y = train_y_by_cluster[cluster]\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=1000, max_depth=12, learning_rate=0.001, random_state=42, n_jobs=2)\n",
    "    xgb_model.fit(train_x, train_y.squeeze())\n",
    "\n",
    "    cluster_xgb[cluster] = xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_train_preds = []\n",
    "rf_train_preds = []\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    train_df = train_df_by_cluster[cluster]\n",
    "\n",
    "    train_x = train_df[x_cols].values.astype(np.float32)\n",
    "    train_y = train_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "    y_scaler = scaler_y_by_cluster[cluster]\n",
    "\n",
    "    net = net_by_cluster[cluster]\n",
    "    rf = cluster_rfs[cluster]\n",
    "\n",
    "    net_preds = net.predict(train_x)\n",
    "    rf_preds = rf.predict(train_x)\n",
    "\n",
    "    train_df['sales_nn'] = net_preds\n",
    "    train_df['sales_rf'] = rf_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Loss Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF RMSLE: 0.4127919069148833\n",
      "NN RMSLE: 0.3906131386756897\n"
     ]
    }
   ],
   "source": [
    "rf_preds = []\n",
    "net_preds = []\n",
    "xgb_preds = []\n",
    "val_y_true = []\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    val_cluster_df = val_df_by_cluster[cluster]\n",
    "    val_x = val_cluster_df[x_cols].values.astype(np.float32)\n",
    "    val_y = val_cluster_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "\n",
    "    rf = cluster_rfs[cluster]\n",
    "    net = net_by_cluster[cluster]\n",
    "\n",
    "    rf_preds.append(scaler_y_by_cluster[cluster].inverse_transform(rf.predict(val_x).reshape(-1, 1)))\n",
    "    net_preds.append(scaler_y_by_cluster[cluster].inverse_transform(net.predict(val_x).reshape(-1, 1)).clip(0))    \n",
    "    #xgb_preds.append(scaler_y_by_cluster[cluster].inverse_transform(cluster_xgb[cluster].predict(val_x).reshape(-1, 1)))\n",
    "    val_y_true.append(scaler_y_by_cluster[cluster].inverse_transform(val_y))\n",
    "\n",
    "rf_preds = np.concatenate(rf_preds)\n",
    "net_preds = np.concatenate(net_preds)\n",
    "#xgb_preds = np.concatenate(xgb_preds)\n",
    "val_y_true = np.concatenate(val_y_true)\n",
    "\n",
    "print(f'RF RMSLE: {rmsle(val_y_true, rf_preds)}')\n",
    "#print(f'XGB RMSLE: {rmsle(val_y_true, xgb_preds)}')\n",
    "print(f'NN RMSLE: {rmsle(val_y_true, net_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store_nbr",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "family",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "onpromotion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "city",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "state",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store_type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "oil",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "h_type_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_description_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_transferred_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_type_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_description_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_transferred_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_of_week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dow_avg_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_1_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_3_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_7_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_1_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_7_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_14_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_avg_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_1_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_3_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_7_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_1_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_7_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_14_transactions",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5da48bd8-230e-44b4-957f-3f8ba8cc4b92",
       "rows": [
        [
         "3000888",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "3.547008547008547",
         "4.0",
         "4.333333333333333",
         "3.4285714285714284",
         "4.0",
         "4.0",
         "2.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0"
        ],
        [
         "3000889",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0"
        ],
        [
         "3000890",
         "1",
         "2",
         "2",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "2.6367521367521367",
         "2.0",
         "2.6666666666666665",
         "3.857142857142857",
         "2.0",
         "2.0",
         "3.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0"
        ],
        [
         "3000891",
         "1",
         "3",
         "20",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "1861.82905982906",
         "2645.0",
         "2418.6666666666665",
         "2456.1428571428573",
         "2418.0",
         "2645.0",
         "2242.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0"
        ],
        [
         "3000892",
         "1",
         "4",
         "0",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "0.1709401709401709",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0"
        ]
       ],
       "shape": {
        "columns": 32,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>store_type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>oil</th>\n",
       "      <th>h_type_nat</th>\n",
       "      <th>h_description_nat</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_1_sales</th>\n",
       "      <th>prev_7_sales</th>\n",
       "      <th>prev_14_sales</th>\n",
       "      <th>dow_avg_transactions</th>\n",
       "      <th>dow_rolling_1_transactions</th>\n",
       "      <th>dow_rolling_3_transactions</th>\n",
       "      <th>dow_rolling_7_transactions</th>\n",
       "      <th>prev_1_transactions</th>\n",
       "      <th>prev_7_transactions</th>\n",
       "      <th>prev_14_transactions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000888</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1861.739316</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1861.739316</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000890</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1861.739316</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000891</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2418.0</td>\n",
       "      <td>2645.0</td>\n",
       "      <td>2242.0</td>\n",
       "      <td>1861.739316</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000892</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1861.739316</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         store_nbr  family  onpromotion  city  state  store_type  cluster  \\\n",
       "id                                                                          \n",
       "3000888          1       0            0     0      0           0       13   \n",
       "3000889          1       1            0     0      0           0       13   \n",
       "3000890          1       2            2     0      0           0       13   \n",
       "3000891          1       3           20     0      0           0       13   \n",
       "3000892          1       4            0     0      0           0       13   \n",
       "\n",
       "          oil  h_type_nat  h_description_nat  ...  prev_1_sales  prev_7_sales  \\\n",
       "id                                            ...                               \n",
       "3000888  46.8           0                  0  ...           4.0           4.0   \n",
       "3000889  46.8           0                  0  ...           0.0           0.0   \n",
       "3000890  46.8           0                  0  ...           2.0           2.0   \n",
       "3000891  46.8           0                  0  ...        2418.0        2645.0   \n",
       "3000892  46.8           0                  0  ...           0.0           0.0   \n",
       "\n",
       "         prev_14_sales  dow_avg_transactions  dow_rolling_1_transactions  \\\n",
       "id                                                                         \n",
       "3000888            2.0           1861.739316                      1892.0   \n",
       "3000889            0.0           1861.739316                      1892.0   \n",
       "3000890            3.0           1861.739316                      1892.0   \n",
       "3000891         2242.0           1861.739316                      1892.0   \n",
       "3000892            0.0           1861.739316                      1892.0   \n",
       "\n",
       "         dow_rolling_3_transactions  dow_rolling_7_transactions  \\\n",
       "id                                                                \n",
       "3000888                      1864.0                 1888.857143   \n",
       "3000889                      1864.0                 1888.857143   \n",
       "3000890                      1864.0                 1888.857143   \n",
       "3000891                      1864.0                 1888.857143   \n",
       "3000892                      1864.0                 1888.857143   \n",
       "\n",
       "         prev_1_transactions  prev_7_transactions  prev_14_transactions  \n",
       "id                                                                       \n",
       "3000888               1766.0               1892.0                1903.0  \n",
       "3000889               1766.0               1892.0                1903.0  \n",
       "3000890               1766.0               1892.0                1903.0  \n",
       "3000891               1766.0               1892.0                1903.0  \n",
       "3000892               1766.0               1892.0                1903.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "25492085-5ec3-49b7-af9d-39b820cfb31e",
       "rows": [
        [
         "3000888",
         "3.9596713"
        ],
        [
         "3000889",
         "0.0"
        ],
        [
         "3000890",
         "5.1113615"
        ],
        [
         "3000891",
         "2302.9902"
        ],
        [
         "3000892",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000888</th>\n",
       "      <td>3.959671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000889</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000890</th>\n",
       "      <td>5.111362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000891</th>\n",
       "      <td>2302.990234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000892</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sales\n",
       "id                  \n",
       "3000888     3.959671\n",
       "3000889     0.000000\n",
       "3000890     5.111362\n",
       "3000891  2302.990234\n",
       "3000892     0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_dir, 'test_data.csv'), index_col=0)\n",
    "display(test_df.head())\n",
    "\n",
    "test_x_by_cluster = {}\n",
    "test_id_by_cluster = {}\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    test_cluster_min_max_scaler, test_cluster_normalize_scaler = scaler_x_by_cluster[cluster]\n",
    "    test_cluster_y_scaler = scaler_y_by_cluster[cluster]\n",
    "\n",
    "    test_cluster_x_df = test_df[test_df[split_col] == cluster]\n",
    "    test_cluster_x_df = test_cluster_x_df.drop(columns=split_col)\n",
    "\n",
    "    test_cluster_x_min_max = test_cluster_x_df[min_max_cols].values.astype(np.float32)\n",
    "    test_cluster_x_normalize = test_cluster_x_df[normalize_cols].values.astype(np.float32)\n",
    "\n",
    "    test_cluster_x_min_max = test_cluster_min_max_scaler.transform(test_cluster_x_min_max)\n",
    "    test_cluster_x_normalize = test_cluster_normalize_scaler.transform(test_cluster_x_normalize)\n",
    "\n",
    "    test_x_by_cluster[cluster] = np.concatenate([test_cluster_x_min_max, test_cluster_x_normalize], axis=1)\n",
    "    test_id_by_cluster[cluster] = test_cluster_x_df.index\n",
    "\n",
    "\n",
    "test_preds_dfs = []\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    test_x = test_x_by_cluster[cluster]\n",
    "    id = test_id_by_cluster[cluster]\n",
    "    #rf = cluster_rfs[cluster]\n",
    "\n",
    "    #pred_rf = scaler_y_by_cluster[cluster].inverse_transform(rf.predict(test_x).reshape(-1, 1))\n",
    "    #pred_xgb = scaler_y_by_cluster[cluster].inverse_transform(cluster_xgb[cluster].predict(test_x).reshape(-1, 1))\n",
    "    pred_nn = scaler_y_by_cluster[cluster].inverse_transform(net_by_cluster[cluster].predict(test_x).reshape(-1, 1)).clip(0)\n",
    "    \n",
    "    cluster_df = pd.DataFrame(np.concatenate([pred_nn], axis=1), index=id, columns=['sales_nn'])\n",
    "    #cluster_df = pd.DataFrame(np.concatenate([pred_rf, pred_nn], axis=1), index=id, columns=['sales_rf', 'sales_nn'])\n",
    "\n",
    "    test_preds_dfs.append(cluster_df)\n",
    "\n",
    "test_preds_df = pd.concat(test_preds_dfs)\n",
    "\n",
    "test_df = test_df.merge(test_preds_df, on='id', how='left')\n",
    "\n",
    "sub_df_nn = test_df[['sales_nn']]\n",
    "#sub_df_rf = test_df[['sales_rf']]\n",
    "#sub_df_xgb = test_df[['sales_xgb']]\n",
    "\n",
    "#sub_df_rf = sub_df_rf.rename(columns={'sales_rf': 'sales'})\n",
    "#sub_df_xgb = sub_df_xgb.rename(columns={'sales_xgb': 'sales'})\n",
    "sub_df_nn = sub_df_nn.rename(columns={'sales_nn': 'sales'})\n",
    "\n",
    "\n",
    "display(sub_df_nn.head())\n",
    "#display(sub_df_rf.head())\n",
    "#display(sub_df_xgb.head())\n",
    "\n",
    "sub_df_nn.to_csv('data/submission_nn.csv')\n",
    "#sub_df_xgb.to_csv('data/submission_xgb.csv')\n",
    "#sub_df_rf.to_csv('data/submission_rf.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
