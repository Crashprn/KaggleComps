{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import EarlyStopping, Checkpoint, LRScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.dataset import Dataset\n",
    "\n",
    "from models import FFNeuralNetwork, LSTMNeuralNetwork, LSTMDataset\n",
    "from utilities import create_scaled_data_by_col, rmsle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "store_nbr",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "family",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "onpromotion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "city",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "state",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store_type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "oil",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "h_type_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_description_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_transferred_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_type_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_description_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_transferred_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_of_week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dow_avg_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_1_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_3_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_7_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_avg_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_1_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_3_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_7_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_1_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_7_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_14_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_1_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_7_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_14_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_payday",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "is_earth_quake",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "is_weekday",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_weekend",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "30586fc7-4768-48bc-ad88-564356e7ee71",
       "rows": [
        [
         "0",
         "2013-02-01 00:00:00",
         "1",
         "0",
         "3.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "False",
         "False",
         "1",
         "0"
        ],
        [
         "1",
         "2013-02-01 00:00:00",
         "1",
         "1",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "False",
         "False",
         "1",
         "0"
        ],
        [
         "2",
         "2013-02-01 00:00:00",
         "1",
         "2",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "False",
         "False",
         "1",
         "0"
        ],
        [
         "3",
         "2013-02-01 00:00:00",
         "1",
         "3",
         "941.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "False",
         "False",
         "1",
         "0"
        ],
        [
         "4",
         "2013-02-01 00:00:00",
         "1",
         "4",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "97.46",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1806.0",
         "2013",
         "2",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "False",
         "False",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 39,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>store_type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>oil</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_1_sales</th>\n",
       "      <th>prev_7_sales</th>\n",
       "      <th>prev_14_sales</th>\n",
       "      <th>prev_1_transactions</th>\n",
       "      <th>prev_7_transactions</th>\n",
       "      <th>prev_14_transactions</th>\n",
       "      <th>is_payday</th>\n",
       "      <th>is_earth_quake</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>941.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>97.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  family  sales  onpromotion  city  state  store_type  \\\n",
       "0 2013-02-01          1       0    3.0            0     0      0           0   \n",
       "1 2013-02-01          1       1    0.0            0     0      0           0   \n",
       "2 2013-02-01          1       2    0.0            0     0      0           0   \n",
       "3 2013-02-01          1       3  941.0            0     0      0           0   \n",
       "4 2013-02-01          1       4    0.0            0     0      0           0   \n",
       "\n",
       "   cluster    oil  ...  prev_1_sales  prev_7_sales  prev_14_sales  \\\n",
       "0       13  97.46  ...           0.0           0.0            0.0   \n",
       "1       13  97.46  ...           0.0           0.0            0.0   \n",
       "2       13  97.46  ...           0.0           0.0            0.0   \n",
       "3       13  97.46  ...           0.0           0.0            0.0   \n",
       "4       13  97.46  ...           0.0           0.0            0.0   \n",
       "\n",
       "   prev_1_transactions  prev_7_transactions  prev_14_transactions  is_payday  \\\n",
       "0                  0.0                  0.0                   0.0      False   \n",
       "1                  0.0                  0.0                   0.0      False   \n",
       "2                  0.0                  0.0                   0.0      False   \n",
       "3                  0.0                  0.0                   0.0      False   \n",
       "4                  0.0                  0.0                   0.0      False   \n",
       "\n",
       "   is_earth_quake  is_weekday  is_weekend  \n",
       "0           False           1           0  \n",
       "1           False           1           0  \n",
       "2           False           1           0  \n",
       "3           False           1           0  \n",
       "4           False           1           0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = 'data/'\n",
    "df = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(by=['date', 'store_nbr'])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['store_nbr', 'city', 'state', 'store_type', 'cluster', 'h_type_nat', 'h_description_nat', 'h_transferred_nat', 'h_type_loc', 'h_description_loc', 'h_transferred_loc', 'month', 'day', 'day_of_week', 'is_payday', 'is_earth_quake', 'is_weekday', 'is_weekend']\n",
      "Index(['date', 'store_nbr', 'family', 'sales', 'onpromotion', 'city', 'state',\n",
      "       'store_type', 'cluster', 'oil', 'h_type_nat', 'h_description_nat',\n",
      "       'h_transferred_nat', 'h_type_loc', 'h_description_loc',\n",
      "       'h_transferred_loc', 'transactions', 'year', 'month', 'day',\n",
      "       'day_of_week', 'dow_avg_sales', 'dow_rolling_1_sales',\n",
      "       'dow_rolling_3_sales', 'dow_rolling_7_sales', 'dow_avg_transactions',\n",
      "       'dow_rolling_1_transactions', 'dow_rolling_3_transactions',\n",
      "       'dow_rolling_7_transactions', 'prev_1_sales', 'prev_7_sales',\n",
      "       'prev_14_sales', 'prev_1_transactions', 'prev_7_transactions',\n",
      "       'prev_14_transactions', 'is_payday', 'is_earth_quake', 'is_weekday',\n",
      "       'is_weekend'],\n",
      "      dtype='object')\n",
      "rows_before 2918916\n",
      "rows_after 26730\n",
      "rows_total 2945646\n"
     ]
    }
   ],
   "source": [
    "min_max_cols = ['store_nbr', 'city', 'state', 'store_type', 'cluster', 'h_type_nat', 'h_description_nat', 'h_transferred_nat',\n",
    "                'h_type_loc', 'h_description_loc', 'h_transferred_loc', 'month', 'day', 'day_of_week', 'is_payday',\n",
    "                'is_earth_quake', 'is_weekday', 'is_weekend'\n",
    "                ]\n",
    "normalize_cols = ['onpromotion', 'oil', 'dow_avg_sales', 'dow_rolling_1_sales', 'dow_rolling_3_sales', 'prev_1_sales',\n",
    "                'prev_7_sales', 'prev_14_sales', 'dow_avg_transactions', 'dow_rolling_1_transactions',\n",
    "                'dow_rolling_3_transactions', 'prev_1_transactions', 'prev_7_transactions', 'prev_14_transactions'\n",
    "                ]\n",
    "x_cols = min_max_cols + normalize_cols\n",
    "y_cols = ['sales']\n",
    "split_col = 'family'\n",
    "\n",
    "print(min_max_cols)\n",
    "print(df.columns)\n",
    "\n",
    "final_run = False\n",
    "\n",
    "if final_run:\n",
    "    train_df = df\n",
    "else:\n",
    "    rows_before = (df['date'] < '2017-08-01')\n",
    "    rows_after = ~rows_before\n",
    "\n",
    "    print('rows_before', rows_before.sum())\n",
    "    print('rows_after', rows_after.sum())\n",
    "    print('rows_total', len(df))\n",
    "\n",
    "    train_df = df[rows_before]\n",
    "    val_df = df[rows_after]\n",
    "\n",
    "train_df_by_cluster = {}\n",
    "scaler_x_by_cluster = {}\n",
    "scaler_y_by_cluster = {}\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    cluster_df, cluster_min_max_scaler, cluster_normalize_scaler, cluster_y_scaler = create_scaled_data_by_col(train_df, min_max_cols, normalize_cols, y_cols, split_col, cluster)\n",
    "    train_df_by_cluster[cluster] = cluster_df\n",
    "    scaler_x_by_cluster[cluster] = (cluster_min_max_scaler, cluster_normalize_scaler)\n",
    "    scaler_y_by_cluster[cluster] = cluster_y_scaler\n",
    "\n",
    "if not final_run:\n",
    "    val_df_by_cluster = {}\n",
    "\n",
    "    for cluster in df[split_col].unique():\n",
    "        val_cluster_min_max_scaler, val_cluster_normalize_scaler = scaler_x_by_cluster[cluster]\n",
    "        val_cluster_y_scaler = scaler_y_by_cluster[cluster]\n",
    "\n",
    "        val_cluster_df = val_df[val_df[split_col] == cluster]\n",
    "        val_cluster_df = val_cluster_df.drop(columns=split_col)\n",
    "\n",
    "        val_cluster_x_min_max = val_cluster_df[min_max_cols].values.astype(np.float32)\n",
    "        val_cluster_x_normalize = val_cluster_df[normalize_cols].values.astype(np.float32)\n",
    "        val_cluster_y = val_cluster_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "\n",
    "        val_cluster_x_min_max = val_cluster_min_max_scaler.transform(val_cluster_x_min_max)\n",
    "        val_cluster_x_normalize = val_cluster_normalize_scaler.transform(val_cluster_x_normalize)\n",
    "        val_cluster_y = val_cluster_y_scaler.transform(val_cluster_y)\n",
    "\n",
    "        val_cluster_df[min_max_cols] = val_cluster_x_min_max\n",
    "        val_cluster_df[normalize_cols] = val_cluster_x_normalize\n",
    "        val_cluster_df[y_cols] = val_cluster_y\n",
    "\n",
    "        val_df_by_cluster[cluster] = val_cluster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_by_cluster = {}\n",
    "train_params = {\n",
    "                \"criterion\": nn.L1Loss,\n",
    "                \"optimizer\": torch.optim.AdamW,\n",
    "                \"optimizer__weight_decay\": 1e-8,\n",
    "                #'train_split' : None,\n",
    "                #\"train_split\": predefined_split(Dataset(val_x, val_y)),\n",
    "                \"lr\": 0.001,\n",
    "                \"batch_size\": 32,\n",
    "                \"max_epochs\": 1000,\n",
    "                \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                \"iterator_train__shuffle\": False,\n",
    "                \"iterator_train__num_workers\": 2,\n",
    "                \"iterator_train__pin_memory\": True,\n",
    "                \"iterator_valid__shuffle\": False,\n",
    "                \"iterator_valid__num_workers\": 2,\n",
    "                \"iterator_valid__pin_memory\": True,\n",
    "                \"verbose\": 2,\n",
    "        }\n",
    "\n",
    "net_params = {\n",
    "    'input_dim': len(x_cols),\n",
    "    'out_dim': 1,\n",
    "    'hidden_dim': 200,\n",
    "    'num_hidden_layers': 6,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.4307\u001b[0m        \u001b[32m0.4698\u001b[0m     +  4.1980\n",
      "      2        \u001b[36m0.4219\u001b[0m        \u001b[32m0.4683\u001b[0m     +  4.1347\n",
      "      3        \u001b[36m0.4196\u001b[0m        0.4694        4.1510\n",
      "      4        \u001b[36m0.4174\u001b[0m        0.4707        4.2521\n",
      "      5        \u001b[36m0.4155\u001b[0m        0.4757        4.1395\n",
      "      6        \u001b[36m0.4136\u001b[0m        0.4734        4.2411\n",
      "      7        \u001b[36m0.4125\u001b[0m        0.4704        4.2442\n",
      "      8        \u001b[36m0.4107\u001b[0m        0.4728        4.3170\n",
      "      9        \u001b[36m0.4091\u001b[0m        0.4697        4.2836\n",
      "     10        \u001b[36m0.4077\u001b[0m        0.4718        4.2592\n",
      "     11        \u001b[36m0.4062\u001b[0m        0.4702        4.2804\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1678\u001b[0m        \u001b[32m0.2509\u001b[0m     +  4.2360\n",
      "      2        \u001b[36m0.1549\u001b[0m        0.2510        4.2950\n",
      "      3        \u001b[36m0.1538\u001b[0m        0.2528        4.3367\n",
      "      4        \u001b[36m0.1528\u001b[0m        0.2550        4.2269\n",
      "      5        0.1528        0.2545        4.2620\n",
      "      6        0.1528        0.2554        4.3451\n",
      "      7        \u001b[36m0.1519\u001b[0m        0.2557        4.3433\n",
      "      8        \u001b[36m0.1506\u001b[0m        0.2565        4.2788\n",
      "      9        0.1512        0.2573        4.2632\n",
      "     10        \u001b[36m0.1500\u001b[0m        0.2586        4.3233\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.3475\u001b[0m        \u001b[32m0.5007\u001b[0m     +  4.2809\n",
      "      2        \u001b[36m0.3367\u001b[0m        0.5082        4.3656\n",
      "      3        \u001b[36m0.3338\u001b[0m        0.5035        4.1999\n",
      "      4        \u001b[36m0.3314\u001b[0m        0.5056        4.3248\n",
      "      5        \u001b[36m0.3290\u001b[0m        0.5101        4.2832\n",
      "      6        \u001b[36m0.3272\u001b[0m        0.5015        4.3515\n",
      "      7        \u001b[36m0.3259\u001b[0m        \u001b[32m0.4945\u001b[0m     +  4.2395\n",
      "      8        \u001b[36m0.3252\u001b[0m        0.4973        4.3235\n",
      "      9        \u001b[36m0.3236\u001b[0m        0.4952        4.2196\n",
      "     10        \u001b[36m0.3226\u001b[0m        0.4972        4.2369\n",
      "     11        \u001b[36m0.3218\u001b[0m        \u001b[32m0.4943\u001b[0m     +  4.2873\n",
      "     12        \u001b[36m0.3207\u001b[0m        \u001b[32m0.4943\u001b[0m     +  4.3350\n",
      "     13        \u001b[36m0.3188\u001b[0m        0.4948        4.2264\n",
      "     14        \u001b[36m0.3187\u001b[0m        0.4972        4.3855\n",
      "     15        \u001b[36m0.3176\u001b[0m        0.4957        4.3128\n",
      "     16        \u001b[36m0.3165\u001b[0m        \u001b[32m0.4901\u001b[0m     +  4.2421\n",
      "     17        \u001b[36m0.3159\u001b[0m        0.4961        4.2383\n",
      "     18        \u001b[36m0.3152\u001b[0m        0.5018        4.3120\n",
      "     19        \u001b[36m0.3151\u001b[0m        0.4959        4.3363\n",
      "     20        \u001b[36m0.3130\u001b[0m        0.4936        4.3070\n",
      "     21        0.3132        0.4919        4.1899\n",
      "     22        \u001b[36m0.3115\u001b[0m        0.4947        4.4453\n",
      "     23        \u001b[36m0.3109\u001b[0m        \u001b[32m0.4895\u001b[0m     +  4.3090\n",
      "     24        \u001b[36m0.3098\u001b[0m        0.4921        4.2455\n",
      "     25        \u001b[36m0.3092\u001b[0m        0.4999        4.3349\n",
      "     26        \u001b[36m0.3078\u001b[0m        0.4907        4.3253\n",
      "     27        \u001b[36m0.3070\u001b[0m        0.4984        4.2156\n",
      "     28        \u001b[36m0.3057\u001b[0m        0.4980        4.2782\n",
      "     29        \u001b[36m0.3047\u001b[0m        0.5064        4.3177\n",
      "     30        \u001b[36m0.3042\u001b[0m        0.5014        4.3507\n",
      "     31        \u001b[36m0.3033\u001b[0m        0.5065        4.4058\n",
      "     32        \u001b[36m0.3029\u001b[0m        0.5043        4.2804\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1771\u001b[0m        \u001b[32m0.2524\u001b[0m     +  4.2712\n",
      "      2        \u001b[36m0.1623\u001b[0m        \u001b[32m0.2481\u001b[0m     +  4.3634\n",
      "      3        \u001b[36m0.1575\u001b[0m        \u001b[32m0.2451\u001b[0m     +  4.2680\n",
      "      4        \u001b[36m0.1542\u001b[0m        0.2489        4.2553\n",
      "      5        \u001b[36m0.1517\u001b[0m        0.2470        4.2615\n",
      "      6        \u001b[36m0.1485\u001b[0m        \u001b[32m0.2429\u001b[0m     +  4.2489\n",
      "      7        \u001b[36m0.1461\u001b[0m        \u001b[32m0.2419\u001b[0m     +  4.2631\n",
      "      8        \u001b[36m0.1437\u001b[0m        0.2449        4.2755\n",
      "      9        \u001b[36m0.1414\u001b[0m        0.2424        4.1918\n",
      "     10        \u001b[36m0.1406\u001b[0m        0.2453        4.2885\n",
      "     11        \u001b[36m0.1385\u001b[0m        0.2425        4.2298\n",
      "     12        \u001b[36m0.1370\u001b[0m        \u001b[32m0.2382\u001b[0m     +  4.2409\n",
      "     13        \u001b[36m0.1361\u001b[0m        \u001b[32m0.2375\u001b[0m     +  4.2168\n",
      "     14        \u001b[36m0.1358\u001b[0m        0.2418        4.2699\n",
      "     15        \u001b[36m0.1347\u001b[0m        \u001b[32m0.2366\u001b[0m     +  4.3489\n",
      "     16        \u001b[36m0.1333\u001b[0m        0.2368        4.2972\n",
      "     17        0.1335        0.2384        4.3968\n",
      "     18        \u001b[36m0.1326\u001b[0m        0.2395        4.2771\n",
      "     19        \u001b[36m0.1324\u001b[0m        \u001b[32m0.2345\u001b[0m     +  4.3644\n",
      "     20        0.1325        0.2473        4.3308\n",
      "     21        \u001b[36m0.1298\u001b[0m        0.2429        4.3622\n",
      "     22        0.1300        0.2488        4.4298\n",
      "     23        \u001b[36m0.1291\u001b[0m        0.2417        4.3255\n",
      "     24        \u001b[36m0.1279\u001b[0m        0.2417        4.3995\n",
      "     25        0.1284        0.2477        4.2406\n",
      "     26        0.1280        0.2431        4.3454\n",
      "     27        \u001b[36m0.1264\u001b[0m        0.2465        4.3638\n",
      "     28        \u001b[36m0.1259\u001b[0m        0.2568        4.3766\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1150\u001b[0m        \u001b[32m0.0197\u001b[0m     +  4.2958\n",
      "      2        \u001b[36m0.1024\u001b[0m        \u001b[32m0.0195\u001b[0m     +  4.3178\n",
      "      3        \u001b[36m0.1004\u001b[0m        \u001b[32m0.0191\u001b[0m     +  4.2740\n",
      "      4        \u001b[36m0.0996\u001b[0m        \u001b[32m0.0186\u001b[0m     +  4.4214\n",
      "      5        \u001b[36m0.0988\u001b[0m        0.0187        4.3444\n",
      "      6        \u001b[36m0.0988\u001b[0m        \u001b[32m0.0183\u001b[0m     +  4.3935\n",
      "      7        \u001b[36m0.0981\u001b[0m        0.0185        4.4099\n",
      "      8        0.0989        0.0188        4.3617\n",
      "      9        \u001b[36m0.0978\u001b[0m        0.0191        5.3830\n",
      "     10        \u001b[36m0.0977\u001b[0m        0.0189        4.9651\n",
      "     11        \u001b[36m0.0970\u001b[0m        0.0194        4.2544\n",
      "     12        \u001b[36m0.0968\u001b[0m        0.0190        4.0513\n",
      "     13        \u001b[36m0.0964\u001b[0m        0.0185        3.9940\n",
      "     14        \u001b[36m0.0959\u001b[0m        0.0190        4.0262\n",
      "     15        \u001b[36m0.0956\u001b[0m        0.0185        4.0497\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1809\u001b[0m        \u001b[32m0.1865\u001b[0m     +  4.1560\n",
      "      2        \u001b[36m0.1648\u001b[0m        \u001b[32m0.1824\u001b[0m     +  4.1197\n",
      "      3        \u001b[36m0.1588\u001b[0m        \u001b[32m0.1814\u001b[0m     +  4.2058\n",
      "      4        \u001b[36m0.1550\u001b[0m        \u001b[32m0.1746\u001b[0m     +  4.1649\n",
      "      5        \u001b[36m0.1508\u001b[0m        0.1747        4.1699\n",
      "      6        \u001b[36m0.1494\u001b[0m        \u001b[32m0.1732\u001b[0m     +  4.0736\n",
      "      7        \u001b[36m0.1468\u001b[0m        \u001b[32m0.1714\u001b[0m     +  4.1021\n",
      "      8        \u001b[36m0.1451\u001b[0m        0.1748        4.1055\n",
      "      9        \u001b[36m0.1443\u001b[0m        0.1736        4.0946\n",
      "     10        \u001b[36m0.1440\u001b[0m        0.1718        4.1653\n",
      "     11        0.1440        0.1721        3.9984\n",
      "     12        \u001b[36m0.1419\u001b[0m        0.1742        3.9931\n",
      "     13        \u001b[36m0.1412\u001b[0m        0.1736        3.9743\n",
      "     14        \u001b[36m0.1408\u001b[0m        0.1726        4.0921\n",
      "     15        \u001b[36m0.1398\u001b[0m        0.1751        3.9895\n",
      "     16        \u001b[36m0.1393\u001b[0m        0.1771        4.0776\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2488\u001b[0m        \u001b[32m0.3126\u001b[0m     +  4.1218\n",
      "      2        \u001b[36m0.2347\u001b[0m        \u001b[32m0.3104\u001b[0m     +  3.9878\n",
      "      3        \u001b[36m0.2288\u001b[0m        0.3124        4.0494\n",
      "      4        \u001b[36m0.2241\u001b[0m        0.3134        4.1828\n",
      "      5        \u001b[36m0.2203\u001b[0m        0.3153        4.2142\n",
      "      6        \u001b[36m0.2170\u001b[0m        0.3152        4.0823\n",
      "      7        \u001b[36m0.2151\u001b[0m        \u001b[32m0.3097\u001b[0m     +  4.1009\n",
      "      8        \u001b[36m0.2128\u001b[0m        0.3138        4.1995\n",
      "      9        \u001b[36m0.2113\u001b[0m        0.3116        4.4984\n",
      "     10        \u001b[36m0.2098\u001b[0m        0.3116        4.1515\n",
      "     11        \u001b[36m0.2098\u001b[0m        0.3101        4.1006\n",
      "     12        \u001b[36m0.2091\u001b[0m        0.3110        4.1306\n",
      "     13        \u001b[36m0.2071\u001b[0m        \u001b[32m0.3049\u001b[0m     +  4.0095\n",
      "     14        \u001b[36m0.2067\u001b[0m        0.3156        4.0896\n",
      "     15        \u001b[36m0.2066\u001b[0m        0.3067        4.0335\n",
      "     16        \u001b[36m0.2046\u001b[0m        0.3124        4.2561\n",
      "     17        \u001b[36m0.2043\u001b[0m        0.3100        4.2430\n",
      "     18        \u001b[36m0.2036\u001b[0m        0.3091        4.2426\n",
      "     19        \u001b[36m0.2026\u001b[0m        0.3110        4.2470\n",
      "     20        \u001b[36m0.2015\u001b[0m        0.3114        4.2692\n",
      "     21        \u001b[36m0.2014\u001b[0m        0.3137        4.1972\n",
      "     22        \u001b[36m0.2012\u001b[0m        0.3079        4.1975\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2457\u001b[0m        \u001b[32m0.3541\u001b[0m     +  4.1649\n",
      "      2        \u001b[36m0.2139\u001b[0m        0.3600        4.2424\n",
      "      3        \u001b[36m0.2020\u001b[0m        0.3846        4.1415\n",
      "      4        \u001b[36m0.1959\u001b[0m        0.3695        4.1057\n",
      "      5        \u001b[36m0.1896\u001b[0m        0.3592        4.0490\n",
      "      6        \u001b[36m0.1852\u001b[0m        \u001b[32m0.3338\u001b[0m     +  4.1499\n",
      "      7        \u001b[36m0.1834\u001b[0m        0.3832        4.1573\n",
      "      8        \u001b[36m0.1809\u001b[0m        0.3529        4.0071\n",
      "      9        \u001b[36m0.1795\u001b[0m        0.3710        4.1537\n",
      "     10        \u001b[36m0.1780\u001b[0m        0.3820        4.1746\n",
      "     11        \u001b[36m0.1773\u001b[0m        0.3660        4.0503\n",
      "     12        \u001b[36m0.1747\u001b[0m        0.3878        4.0941\n",
      "     13        \u001b[36m0.1736\u001b[0m        0.3870        3.9750\n",
      "     14        \u001b[36m0.1729\u001b[0m        0.3752        3.9381\n",
      "     15        0.1735        0.3817        4.0695\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1517\u001b[0m        \u001b[32m0.1600\u001b[0m     +  4.0357\n",
      "      2        \u001b[36m0.1367\u001b[0m        0.1606        3.9940\n",
      "      3        \u001b[36m0.1318\u001b[0m        \u001b[32m0.1539\u001b[0m     +  4.0729\n",
      "      4        \u001b[36m0.1260\u001b[0m        \u001b[32m0.1531\u001b[0m     +  4.2444\n",
      "      5        \u001b[36m0.1222\u001b[0m        \u001b[32m0.1494\u001b[0m     +  4.2224\n",
      "      6        \u001b[36m0.1204\u001b[0m        0.1531        4.2387\n",
      "      7        \u001b[36m0.1186\u001b[0m        0.1577        4.3109\n",
      "      8        \u001b[36m0.1176\u001b[0m        0.1525        4.2510\n",
      "      9        \u001b[36m0.1164\u001b[0m        0.1510        4.2506\n",
      "     10        \u001b[36m0.1156\u001b[0m        0.1538        4.2569\n",
      "     11        \u001b[36m0.1143\u001b[0m        0.1495        4.3177\n",
      "     12        \u001b[36m0.1138\u001b[0m        0.1513        4.4597\n",
      "     13        \u001b[36m0.1135\u001b[0m        0.1529        4.1657\n",
      "     14        \u001b[36m0.1124\u001b[0m        \u001b[32m0.1475\u001b[0m     +  4.1104\n",
      "     15        \u001b[36m0.1119\u001b[0m        0.1510        4.0887\n",
      "     16        0.1120        0.1562        4.1371\n",
      "     17        \u001b[36m0.1114\u001b[0m        0.1544        4.0401\n",
      "     18        \u001b[36m0.1104\u001b[0m        0.1525        4.2124\n",
      "     19        \u001b[36m0.1100\u001b[0m        0.1506        4.3824\n",
      "     20        \u001b[36m0.1100\u001b[0m        0.1533        4.4602\n",
      "     21        \u001b[36m0.1100\u001b[0m        0.1531        4.4145\n",
      "     22        \u001b[36m0.1094\u001b[0m        0.1496        4.5031\n",
      "     23        \u001b[36m0.1083\u001b[0m        0.1501        4.4003\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2133\u001b[0m        \u001b[32m0.2150\u001b[0m     +  4.4854\n",
      "      2        \u001b[36m0.1908\u001b[0m        \u001b[32m0.1971\u001b[0m     +  4.4571\n",
      "      3        \u001b[36m0.1803\u001b[0m        \u001b[32m0.1884\u001b[0m     +  4.4838\n",
      "      4        \u001b[36m0.1755\u001b[0m        \u001b[32m0.1883\u001b[0m     +  4.5340\n",
      "      5        \u001b[36m0.1729\u001b[0m        0.1899        4.5118\n",
      "      6        \u001b[36m0.1707\u001b[0m        0.1931        4.5052\n",
      "      7        \u001b[36m0.1688\u001b[0m        \u001b[32m0.1880\u001b[0m     +  4.5001\n",
      "      8        \u001b[36m0.1672\u001b[0m        0.1880        4.4579\n",
      "      9        \u001b[36m0.1658\u001b[0m        \u001b[32m0.1869\u001b[0m     +  4.5098\n",
      "     10        \u001b[36m0.1649\u001b[0m        0.1881        4.4872\n",
      "     11        \u001b[36m0.1648\u001b[0m        0.1902        4.4345\n",
      "     12        \u001b[36m0.1631\u001b[0m        0.1968        4.2824\n",
      "     13        \u001b[36m0.1623\u001b[0m        0.2004        4.2914\n",
      "     14        \u001b[36m0.1621\u001b[0m        0.1945        4.2920\n",
      "     15        \u001b[36m0.1609\u001b[0m        0.2064        4.3563\n",
      "     16        \u001b[36m0.1600\u001b[0m        0.1878        4.3271\n",
      "     17        0.1602        0.1968        4.2868\n",
      "     18        \u001b[36m0.1586\u001b[0m        0.1957        4.2951\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2224\u001b[0m        \u001b[32m0.2180\u001b[0m     +  4.3677\n",
      "      2        \u001b[36m0.2054\u001b[0m        0.2204        4.3364\n",
      "      3        \u001b[36m0.2007\u001b[0m        0.2242        4.2659\n",
      "      4        \u001b[36m0.1965\u001b[0m        0.2256        4.2551\n",
      "      5        \u001b[36m0.1925\u001b[0m        0.2263        4.3915\n",
      "      6        \u001b[36m0.1904\u001b[0m        0.2311        4.4313\n",
      "      7        \u001b[36m0.1884\u001b[0m        0.2310        4.3330\n",
      "      8        \u001b[36m0.1866\u001b[0m        0.2311        4.3699\n",
      "      9        \u001b[36m0.1863\u001b[0m        0.2315        4.2571\n",
      "     10        \u001b[36m0.1850\u001b[0m        0.2291        4.2429\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1475\u001b[0m        \u001b[32m0.0761\u001b[0m     +  4.2673\n",
      "      2        \u001b[36m0.1372\u001b[0m        0.0798        4.3435\n",
      "      3        \u001b[36m0.1356\u001b[0m        0.0796        4.2313\n",
      "      4        \u001b[36m0.1337\u001b[0m        0.0806        4.2987\n",
      "      5        \u001b[36m0.1300\u001b[0m        0.0819        4.2428\n",
      "      6        \u001b[36m0.1261\u001b[0m        0.0816        4.1350\n",
      "      7        \u001b[36m0.1227\u001b[0m        0.0828        4.2384\n",
      "      8        \u001b[36m0.1206\u001b[0m        0.0801        4.3322\n",
      "      9        \u001b[36m0.1181\u001b[0m        0.0808        4.2556\n",
      "     10        \u001b[36m0.1173\u001b[0m        0.0825        4.2481\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2125\u001b[0m        \u001b[32m0.2150\u001b[0m     +  4.3469\n",
      "      2        \u001b[36m0.1851\u001b[0m        \u001b[32m0.2035\u001b[0m     +  4.3921\n",
      "      3        \u001b[36m0.1752\u001b[0m        0.2065        4.3203\n",
      "      4        \u001b[36m0.1692\u001b[0m        0.2058        4.3253\n",
      "      5        \u001b[36m0.1643\u001b[0m        0.2088        4.2765\n",
      "      6        \u001b[36m0.1609\u001b[0m        0.2077        4.3058\n",
      "      7        \u001b[36m0.1592\u001b[0m        0.2169        4.3029\n",
      "      8        \u001b[36m0.1582\u001b[0m        0.2195        4.3269\n",
      "      9        \u001b[36m0.1566\u001b[0m        0.2199        4.3053\n",
      "     10        \u001b[36m0.1556\u001b[0m        0.2172        4.3267\n",
      "     11        \u001b[36m0.1541\u001b[0m        0.2129        4.2611\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2428\u001b[0m        \u001b[32m0.3289\u001b[0m     +  4.3449\n",
      "      2        \u001b[36m0.2337\u001b[0m        0.3553        4.3794\n",
      "      3        \u001b[36m0.2316\u001b[0m        0.3541        4.3525\n",
      "      4        \u001b[36m0.2291\u001b[0m        0.3492        4.2758\n",
      "      5        \u001b[36m0.2276\u001b[0m        0.3389        4.3888\n",
      "      6        \u001b[36m0.2264\u001b[0m        0.3404        4.2317\n",
      "      7        \u001b[36m0.2246\u001b[0m        \u001b[32m0.3189\u001b[0m     +  4.3873\n",
      "      8        \u001b[36m0.2243\u001b[0m        0.3255        4.3163\n",
      "      9        \u001b[36m0.2227\u001b[0m        0.3303        4.2211\n",
      "     10        \u001b[36m0.2222\u001b[0m        0.3494        4.3295\n",
      "     11        \u001b[36m0.2211\u001b[0m        0.3454        4.2878\n",
      "     12        \u001b[36m0.2205\u001b[0m        0.3408        4.3322\n",
      "     13        \u001b[36m0.2199\u001b[0m        0.3433        4.3237\n",
      "     14        \u001b[36m0.2192\u001b[0m        0.3413        4.3787\n",
      "     15        \u001b[36m0.2185\u001b[0m        0.3501        4.3238\n",
      "     16        \u001b[36m0.2175\u001b[0m        0.3364        4.3442\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.5589\u001b[0m        \u001b[32m0.6397\u001b[0m     +  4.3009\n",
      "      2        \u001b[36m0.5487\u001b[0m        \u001b[32m0.6342\u001b[0m     +  4.3797\n",
      "      3        \u001b[36m0.5440\u001b[0m        0.6366        4.2927\n",
      "      4        \u001b[36m0.5417\u001b[0m        \u001b[32m0.6322\u001b[0m     +  4.3381\n",
      "      5        \u001b[36m0.5405\u001b[0m        0.6373        4.2968\n",
      "      6        \u001b[36m0.5395\u001b[0m        0.6397        4.2564\n",
      "      7        \u001b[36m0.5389\u001b[0m        \u001b[32m0.6294\u001b[0m     +  4.3660\n",
      "      8        \u001b[36m0.5379\u001b[0m        0.6338        4.3174\n",
      "      9        \u001b[36m0.5370\u001b[0m        0.6294        4.3115\n",
      "     10        \u001b[36m0.5363\u001b[0m        0.6388        4.3441\n",
      "     11        \u001b[36m0.5346\u001b[0m        0.6352        4.2712\n",
      "     12        \u001b[36m0.5341\u001b[0m        0.6303        4.2877\n",
      "     13        0.5342        0.6325        4.3440\n",
      "     14        \u001b[36m0.5333\u001b[0m        0.6486        4.3571\n",
      "     15        \u001b[36m0.5324\u001b[0m        0.6358        4.2328\n",
      "     16        \u001b[36m0.5321\u001b[0m        0.6333        4.3135\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2766\u001b[0m        \u001b[32m0.3082\u001b[0m     +  4.3104\n",
      "      2        \u001b[36m0.2670\u001b[0m        0.3134        4.1967\n",
      "      3        \u001b[36m0.2641\u001b[0m        0.3185        4.3164\n",
      "      4        \u001b[36m0.2615\u001b[0m        0.3230        4.2510\n",
      "      5        \u001b[36m0.2593\u001b[0m        0.3202        4.3273\n",
      "      6        \u001b[36m0.2586\u001b[0m        0.3289        4.2274\n",
      "      7        \u001b[36m0.2565\u001b[0m        0.3222        4.3068\n",
      "      8        \u001b[36m0.2564\u001b[0m        0.3242        4.2432\n",
      "      9        \u001b[36m0.2541\u001b[0m        0.3301        4.3314\n",
      "     10        \u001b[36m0.2529\u001b[0m        0.3348        4.4801\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2230\u001b[0m        \u001b[32m0.3729\u001b[0m     +  4.3226\n",
      "      2        \u001b[36m0.2111\u001b[0m        \u001b[32m0.3588\u001b[0m     +  4.4144\n",
      "      3        \u001b[36m0.2082\u001b[0m        \u001b[32m0.3579\u001b[0m     +  4.5334\n",
      "      4        \u001b[36m0.2066\u001b[0m        0.3580        4.2812\n",
      "      5        \u001b[36m0.2044\u001b[0m        0.3586        4.2593\n",
      "      6        \u001b[36m0.2026\u001b[0m        \u001b[32m0.3557\u001b[0m     +  4.3513\n",
      "      7        \u001b[36m0.2017\u001b[0m        \u001b[32m0.3557\u001b[0m     +  4.3678\n",
      "      8        \u001b[36m0.2009\u001b[0m        \u001b[32m0.3543\u001b[0m     +  4.3631\n",
      "      9        \u001b[36m0.1997\u001b[0m        \u001b[32m0.3534\u001b[0m     +  4.3548\n",
      "     10        \u001b[36m0.1984\u001b[0m        \u001b[32m0.3509\u001b[0m     +  4.3536\n",
      "     11        \u001b[36m0.1976\u001b[0m        \u001b[32m0.3502\u001b[0m     +  4.2934\n",
      "     12        \u001b[36m0.1963\u001b[0m        0.3508        4.2980\n",
      "     13        \u001b[36m0.1960\u001b[0m        \u001b[32m0.3459\u001b[0m     +  4.3553\n",
      "     14        \u001b[36m0.1951\u001b[0m        0.3564        4.3355\n",
      "     15        \u001b[36m0.1940\u001b[0m        0.3473        4.3250\n",
      "     16        \u001b[36m0.1935\u001b[0m        \u001b[32m0.3389\u001b[0m     +  4.3715\n",
      "     17        \u001b[36m0.1929\u001b[0m        0.3494        4.2473\n",
      "     18        \u001b[36m0.1915\u001b[0m        0.3530        4.3411\n",
      "     19        \u001b[36m0.1905\u001b[0m        0.3523        4.3012\n",
      "     20        \u001b[36m0.1903\u001b[0m        0.3528        4.3034\n",
      "     21        \u001b[36m0.1900\u001b[0m        0.3532        4.3212\n",
      "     22        \u001b[36m0.1890\u001b[0m        0.3510        4.3904\n",
      "     23        \u001b[36m0.1884\u001b[0m        0.3524        4.4459\n",
      "     24        \u001b[36m0.1883\u001b[0m        0.3546        4.4833\n",
      "     25        \u001b[36m0.1877\u001b[0m        0.3492        4.4317\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.4211\u001b[0m        \u001b[32m0.2058\u001b[0m     +  4.3964\n",
      "      2        \u001b[36m0.4041\u001b[0m        \u001b[32m0.1977\u001b[0m     +  4.3906\n",
      "      3        \u001b[36m0.4000\u001b[0m        \u001b[32m0.1946\u001b[0m     +  4.3036\n",
      "      4        \u001b[36m0.3988\u001b[0m        0.1959        4.2737\n",
      "      5        \u001b[36m0.3977\u001b[0m        \u001b[32m0.1929\u001b[0m     +  4.2890\n",
      "      6        \u001b[36m0.3963\u001b[0m        \u001b[32m0.1928\u001b[0m     +  4.4223\n",
      "      7        0.3966        \u001b[32m0.1923\u001b[0m     +  4.2657\n",
      "      8        \u001b[36m0.3954\u001b[0m        0.2038        4.4266\n",
      "      9        \u001b[36m0.3950\u001b[0m        0.1996        4.3828\n",
      "     10        \u001b[36m0.3947\u001b[0m        0.1963        4.3712\n",
      "     11        \u001b[36m0.3945\u001b[0m        0.2015        4.4476\n",
      "     12        \u001b[36m0.3937\u001b[0m        0.1998        4.3478\n",
      "     13        0.3940        0.1983        4.3463\n",
      "     14        \u001b[36m0.3935\u001b[0m        0.1927        4.4615\n",
      "     15        \u001b[36m0.3930\u001b[0m        0.1962        4.3571\n",
      "     16        \u001b[36m0.3923\u001b[0m        0.1990        4.3891\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2070\u001b[0m        \u001b[32m0.3233\u001b[0m     +  4.4217\n",
      "      2        \u001b[36m0.1737\u001b[0m        \u001b[32m0.3037\u001b[0m     +  4.4294\n",
      "      3        \u001b[36m0.1578\u001b[0m        \u001b[32m0.2929\u001b[0m     +  4.4370\n",
      "      4        \u001b[36m0.1517\u001b[0m        \u001b[32m0.2913\u001b[0m     +  4.2399\n",
      "      5        \u001b[36m0.1466\u001b[0m        \u001b[32m0.2843\u001b[0m     +  4.3671\n",
      "      6        \u001b[36m0.1413\u001b[0m        \u001b[32m0.2806\u001b[0m     +  4.4152\n",
      "      7        \u001b[36m0.1390\u001b[0m        0.2929        4.4231\n",
      "      8        \u001b[36m0.1362\u001b[0m        0.2892        4.3511\n",
      "      9        \u001b[36m0.1329\u001b[0m        0.2845        4.3521\n",
      "     10        \u001b[36m0.1301\u001b[0m        \u001b[32m0.2802\u001b[0m     +  4.4142\n",
      "     11        \u001b[36m0.1288\u001b[0m        \u001b[32m0.2760\u001b[0m     +  4.4027\n",
      "     12        \u001b[36m0.1262\u001b[0m        \u001b[32m0.2735\u001b[0m     +  4.3413\n",
      "     13        \u001b[36m0.1245\u001b[0m        0.2775        4.3896\n",
      "     14        \u001b[36m0.1236\u001b[0m        0.2802        4.3723\n",
      "     15        \u001b[36m0.1230\u001b[0m        0.2902        4.5702\n",
      "     16        \u001b[36m0.1214\u001b[0m        0.2881        4.3781\n",
      "     17        \u001b[36m0.1213\u001b[0m        0.2814        4.3880\n",
      "     18        \u001b[36m0.1203\u001b[0m        0.2970        4.4309\n",
      "     19        \u001b[36m0.1203\u001b[0m        0.2986        4.4392\n",
      "     20        \u001b[36m0.1195\u001b[0m        0.2970        4.4872\n",
      "     21        \u001b[36m0.1178\u001b[0m        0.2871        4.4188\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2259\u001b[0m        \u001b[32m0.2561\u001b[0m     +  4.4177\n",
      "      2        \u001b[36m0.2081\u001b[0m        0.2597        4.4265\n",
      "      3        \u001b[36m0.1978\u001b[0m        0.2933        4.4619\n",
      "      4        \u001b[36m0.1919\u001b[0m        0.2729        4.4145\n",
      "      5        \u001b[36m0.1888\u001b[0m        \u001b[32m0.2537\u001b[0m     +  4.4392\n",
      "      6        \u001b[36m0.1867\u001b[0m        \u001b[32m0.2518\u001b[0m     +  4.5099\n",
      "      7        \u001b[36m0.1855\u001b[0m        0.2527        4.3712\n",
      "      8        \u001b[36m0.1854\u001b[0m        \u001b[32m0.2516\u001b[0m     +  4.4079\n",
      "      9        \u001b[36m0.1835\u001b[0m        0.2540        4.4831\n",
      "     10        \u001b[36m0.1811\u001b[0m        \u001b[32m0.2513\u001b[0m     +  4.4409\n",
      "     11        0.1812        0.2711        4.3968\n",
      "     12        \u001b[36m0.1800\u001b[0m        0.2629        4.4256\n",
      "     13        \u001b[36m0.1783\u001b[0m        0.2790        4.4681\n",
      "     14        \u001b[36m0.1779\u001b[0m        0.2579        4.4342\n",
      "     15        \u001b[36m0.1772\u001b[0m        0.2763        4.4955\n",
      "     16        0.1779        0.2731        4.4571\n",
      "     17        \u001b[36m0.1765\u001b[0m        0.2594        4.4234\n",
      "     18        \u001b[36m0.1751\u001b[0m        0.2757        4.4142\n",
      "     19        \u001b[36m0.1746\u001b[0m        0.2647        4.4543\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2278\u001b[0m        \u001b[32m0.3833\u001b[0m     +  4.4612\n",
      "      2        \u001b[36m0.2173\u001b[0m        \u001b[32m0.3784\u001b[0m     +  4.4770\n",
      "      3        \u001b[36m0.2158\u001b[0m        \u001b[32m0.3730\u001b[0m     +  4.4004\n",
      "      4        \u001b[36m0.2137\u001b[0m        \u001b[32m0.3716\u001b[0m     +  4.3424\n",
      "      5        \u001b[36m0.2132\u001b[0m        0.3726        4.3652\n",
      "      6        \u001b[36m0.2119\u001b[0m        0.3726        4.4807\n",
      "      7        \u001b[36m0.2107\u001b[0m        \u001b[32m0.3658\u001b[0m     +  4.4819\n",
      "      8        \u001b[36m0.2097\u001b[0m        0.3715        4.5869\n",
      "      9        0.2099        0.3716        4.4783\n",
      "     10        \u001b[36m0.2089\u001b[0m        0.3719        4.4442\n",
      "     11        \u001b[36m0.2075\u001b[0m        0.3728        4.5026\n",
      "     12        0.2075        0.3695        4.4374\n",
      "     13        \u001b[36m0.2061\u001b[0m        0.3741        4.4315\n",
      "     14        \u001b[36m0.2060\u001b[0m        0.3773        4.4749\n",
      "     15        \u001b[36m0.2056\u001b[0m        0.3768        4.4009\n",
      "     16        \u001b[36m0.2051\u001b[0m        0.3786        4.4918\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.3727\u001b[0m        \u001b[32m0.4067\u001b[0m     +  4.5219\n",
      "      2        \u001b[36m0.3660\u001b[0m        \u001b[32m0.4034\u001b[0m     +  4.5110\n",
      "      3        \u001b[36m0.3635\u001b[0m        \u001b[32m0.4009\u001b[0m     +  4.4793\n",
      "      4        \u001b[36m0.3617\u001b[0m        0.4012        4.4277\n",
      "      5        \u001b[36m0.3595\u001b[0m        \u001b[32m0.3997\u001b[0m     +  4.3147\n",
      "      6        \u001b[36m0.3578\u001b[0m        \u001b[32m0.3972\u001b[0m     +  4.4335\n",
      "      7        \u001b[36m0.3562\u001b[0m        0.4014        4.4574\n",
      "      8        \u001b[36m0.3552\u001b[0m        0.4088        4.4449\n",
      "      9        \u001b[36m0.3545\u001b[0m        0.4009        4.6099\n",
      "     10        \u001b[36m0.3531\u001b[0m        0.4004        4.4387\n",
      "     11        \u001b[36m0.3520\u001b[0m        0.4041        4.4118\n",
      "     12        \u001b[36m0.3510\u001b[0m        0.4009        4.5149\n",
      "     13        \u001b[36m0.3497\u001b[0m        0.3989        4.4893\n",
      "     14        \u001b[36m0.3486\u001b[0m        0.4006        4.4603\n",
      "     15        \u001b[36m0.3482\u001b[0m        0.3998        4.4789\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2613\u001b[0m        \u001b[32m0.2292\u001b[0m     +  4.5459\n",
      "      2        \u001b[36m0.2425\u001b[0m        \u001b[32m0.2246\u001b[0m     +  4.4323\n",
      "      3        \u001b[36m0.2365\u001b[0m        0.2325        4.4557\n",
      "      4        \u001b[36m0.2326\u001b[0m        0.2324        4.4522\n",
      "      5        \u001b[36m0.2294\u001b[0m        0.2413        4.4664\n",
      "      6        \u001b[36m0.2283\u001b[0m        0.2375        4.4554\n",
      "      7        \u001b[36m0.2256\u001b[0m        0.2384        4.4626\n",
      "      8        \u001b[36m0.2241\u001b[0m        0.2353        4.4703\n",
      "      9        \u001b[36m0.2208\u001b[0m        0.2507        4.3908\n",
      "     10        \u001b[36m0.2198\u001b[0m        0.2546        4.3638\n",
      "     11        \u001b[36m0.2175\u001b[0m        0.2444        4.3098\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2349\u001b[0m        \u001b[32m0.4418\u001b[0m     +  4.2676\n",
      "      2        \u001b[36m0.2233\u001b[0m        \u001b[32m0.4392\u001b[0m     +  4.4144\n",
      "      3        \u001b[36m0.2198\u001b[0m        \u001b[32m0.4317\u001b[0m     +  4.3821\n",
      "      4        \u001b[36m0.2181\u001b[0m        0.4329        4.3929\n",
      "      5        \u001b[36m0.2159\u001b[0m        \u001b[32m0.4303\u001b[0m     +  4.3161\n",
      "      6        \u001b[36m0.2148\u001b[0m        0.4315        4.3699\n",
      "      7        \u001b[36m0.2136\u001b[0m        0.4333        4.3807\n",
      "      8        \u001b[36m0.2126\u001b[0m        0.4331        4.3375\n",
      "      9        \u001b[36m0.2114\u001b[0m        0.4313        4.3552\n",
      "     10        \u001b[36m0.2101\u001b[0m        0.4310        4.3016\n",
      "     11        \u001b[36m0.2097\u001b[0m        0.4317        4.3672\n",
      "     12        \u001b[36m0.2084\u001b[0m        0.4316        4.2952\n",
      "     13        \u001b[36m0.2076\u001b[0m        0.4321        4.3258\n",
      "     14        \u001b[36m0.2076\u001b[0m        0.4330        4.3182\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1380\u001b[0m        \u001b[32m0.1251\u001b[0m     +  4.3620\n",
      "      2        \u001b[36m0.1258\u001b[0m        \u001b[32m0.1202\u001b[0m     +  4.4195\n",
      "      3        \u001b[36m0.1200\u001b[0m        \u001b[32m0.1168\u001b[0m     +  4.2968\n",
      "      4        \u001b[36m0.1171\u001b[0m        \u001b[32m0.1141\u001b[0m     +  4.3587\n",
      "      5        \u001b[36m0.1138\u001b[0m        \u001b[32m0.1119\u001b[0m     +  4.3818\n",
      "      6        \u001b[36m0.1128\u001b[0m        0.1130        4.2670\n",
      "      7        \u001b[36m0.1113\u001b[0m        \u001b[32m0.1106\u001b[0m     +  4.3368\n",
      "      8        \u001b[36m0.1106\u001b[0m        \u001b[32m0.1095\u001b[0m     +  4.3261\n",
      "      9        \u001b[36m0.1098\u001b[0m        0.1107        4.3882\n",
      "     10        \u001b[36m0.1091\u001b[0m        \u001b[32m0.1073\u001b[0m     +  4.3830\n",
      "     11        \u001b[36m0.1089\u001b[0m        0.1081        4.2967\n",
      "     12        \u001b[36m0.1074\u001b[0m        0.1079        4.3442\n",
      "     13        \u001b[36m0.1072\u001b[0m        0.1079        4.3058\n",
      "     14        \u001b[36m0.1066\u001b[0m        0.1087        4.3228\n",
      "     15        \u001b[36m0.1063\u001b[0m        \u001b[32m0.1069\u001b[0m     +  4.3146\n",
      "     16        \u001b[36m0.1061\u001b[0m        \u001b[32m0.1061\u001b[0m     +  4.3023\n",
      "     17        \u001b[36m0.1057\u001b[0m        0.1062        4.2659\n",
      "     18        \u001b[36m0.1054\u001b[0m        \u001b[32m0.1057\u001b[0m     +  4.2931\n",
      "     19        \u001b[36m0.1051\u001b[0m        0.1083        4.4092\n",
      "     20        \u001b[36m0.1044\u001b[0m        0.1086        4.4519\n",
      "     21        0.1049        0.1076        4.4508\n",
      "     22        \u001b[36m0.1039\u001b[0m        0.1084        4.4094\n",
      "     23        \u001b[36m0.1036\u001b[0m        0.1100        4.4144\n",
      "     24        0.1037        0.1084        4.4431\n",
      "     25        \u001b[36m0.1029\u001b[0m        0.1081        4.3669\n",
      "     26        0.1037        0.1071        4.3206\n",
      "     27        \u001b[36m0.1028\u001b[0m        0.1069        4.3236\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2420\u001b[0m        \u001b[32m0.2816\u001b[0m     +  4.3417\n",
      "      2        \u001b[36m0.2115\u001b[0m        0.3055        4.4288\n",
      "      3        \u001b[36m0.2009\u001b[0m        \u001b[32m0.2814\u001b[0m     +  4.3467\n",
      "      4        \u001b[36m0.1955\u001b[0m        \u001b[32m0.2796\u001b[0m     +  4.3632\n",
      "      5        \u001b[36m0.1913\u001b[0m        0.2913        4.4017\n",
      "      6        \u001b[36m0.1894\u001b[0m        0.2949        4.3926\n",
      "      7        \u001b[36m0.1867\u001b[0m        0.3160        4.3377\n",
      "      8        \u001b[36m0.1839\u001b[0m        0.3038        4.3444\n",
      "      9        0.1844        0.3049        4.3449\n",
      "     10        \u001b[36m0.1818\u001b[0m        0.3084        4.3716\n",
      "     11        \u001b[36m0.1813\u001b[0m        0.3004        4.4095\n",
      "     12        \u001b[36m0.1796\u001b[0m        0.3077        4.3043\n",
      "     13        \u001b[36m0.1780\u001b[0m        0.3029        4.2557\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2144\u001b[0m        \u001b[32m0.3715\u001b[0m     +  4.4338\n",
      "      2        \u001b[36m0.2054\u001b[0m        \u001b[32m0.3699\u001b[0m     +  4.3490\n",
      "      3        \u001b[36m0.2002\u001b[0m        \u001b[32m0.3674\u001b[0m     +  4.3847\n",
      "      4        \u001b[36m0.1977\u001b[0m        \u001b[32m0.3671\u001b[0m     +  4.4370\n",
      "      5        \u001b[36m0.1924\u001b[0m        \u001b[32m0.3633\u001b[0m     +  4.3467\n",
      "      6        \u001b[36m0.1894\u001b[0m        0.3662        4.3579\n",
      "      7        \u001b[36m0.1874\u001b[0m        0.3652        4.4154\n",
      "      8        \u001b[36m0.1854\u001b[0m        0.3645        4.3109\n",
      "      9        \u001b[36m0.1839\u001b[0m        0.3644        4.3408\n",
      "     10        \u001b[36m0.1825\u001b[0m        0.3666        4.5077\n",
      "     11        0.1826        0.3647        4.3489\n",
      "     12        \u001b[36m0.1817\u001b[0m        0.3663        4.3634\n",
      "     13        \u001b[36m0.1807\u001b[0m        0.3647        4.4379\n",
      "     14        \u001b[36m0.1805\u001b[0m        0.3655        4.3694\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2565\u001b[0m        \u001b[32m0.3506\u001b[0m     +  4.4953\n",
      "      2        \u001b[36m0.2375\u001b[0m        \u001b[32m0.3406\u001b[0m     +  4.4787\n",
      "      3        \u001b[36m0.2276\u001b[0m        \u001b[32m0.3401\u001b[0m     +  4.3988\n",
      "      4        \u001b[36m0.2227\u001b[0m        \u001b[32m0.3378\u001b[0m     +  4.4208\n",
      "      5        \u001b[36m0.2182\u001b[0m        \u001b[32m0.3377\u001b[0m     +  4.3528\n",
      "      6        \u001b[36m0.2153\u001b[0m        0.3382        4.3638\n",
      "      7        \u001b[36m0.2139\u001b[0m        \u001b[32m0.3366\u001b[0m     +  4.4338\n",
      "      8        \u001b[36m0.2121\u001b[0m        \u001b[32m0.3348\u001b[0m     +  4.3539\n",
      "      9        \u001b[36m0.2099\u001b[0m        0.3351        4.1575\n",
      "     10        \u001b[36m0.2085\u001b[0m        \u001b[32m0.3336\u001b[0m     +  4.1377\n",
      "     11        \u001b[36m0.2077\u001b[0m        0.3345        4.1976\n",
      "     12        \u001b[36m0.2063\u001b[0m        \u001b[32m0.3328\u001b[0m     +  4.2023\n",
      "     13        \u001b[36m0.2059\u001b[0m        0.3383        4.1124\n",
      "     14        \u001b[36m0.2048\u001b[0m        0.3332        4.2003\n",
      "     15        \u001b[36m0.2045\u001b[0m        0.3404        4.1542\n",
      "     16        \u001b[36m0.2032\u001b[0m        0.3335        4.2143\n",
      "     17        \u001b[36m0.2023\u001b[0m        0.3361        4.2258\n",
      "     18        \u001b[36m0.2017\u001b[0m        0.3370        4.1951\n",
      "     19        \u001b[36m0.2006\u001b[0m        0.3391        4.1709\n",
      "     20        0.2010        0.3356        4.1695\n",
      "     21        \u001b[36m0.1995\u001b[0m        0.3419        4.1955\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1590\u001b[0m        \u001b[32m0.1362\u001b[0m     +  4.1583\n",
      "      2        \u001b[36m0.1437\u001b[0m        \u001b[32m0.1336\u001b[0m     +  4.1304\n",
      "      3        \u001b[36m0.1385\u001b[0m        \u001b[32m0.1313\u001b[0m     +  4.1948\n",
      "      4        \u001b[36m0.1323\u001b[0m        \u001b[32m0.1271\u001b[0m     +  4.1664\n",
      "      5        \u001b[36m0.1279\u001b[0m        \u001b[32m0.1247\u001b[0m     +  4.2345\n",
      "      6        \u001b[36m0.1260\u001b[0m        0.1252        4.2619\n",
      "      7        \u001b[36m0.1242\u001b[0m        0.1265        4.1564\n",
      "      8        \u001b[36m0.1236\u001b[0m        0.1251        4.1020\n",
      "      9        \u001b[36m0.1222\u001b[0m        0.1285        4.1314\n",
      "     10        \u001b[36m0.1213\u001b[0m        0.1287        4.2469\n",
      "     11        \u001b[36m0.1206\u001b[0m        \u001b[32m0.1232\u001b[0m     +  4.3453\n",
      "     12        \u001b[36m0.1195\u001b[0m        0.1249        4.3620\n",
      "     13        \u001b[36m0.1191\u001b[0m        0.1256        4.3654\n",
      "     14        \u001b[36m0.1185\u001b[0m        0.1248        4.1692\n",
      "     15        \u001b[36m0.1179\u001b[0m        0.1284        4.0875\n",
      "     16        \u001b[36m0.1171\u001b[0m        0.1319        4.1574\n",
      "     17        \u001b[36m0.1170\u001b[0m        0.1319        4.1498\n",
      "     18        \u001b[36m0.1162\u001b[0m        0.1300        4.1752\n",
      "     19        0.1163        0.1335        4.1903\n",
      "     20        \u001b[36m0.1156\u001b[0m        0.1364        4.1461\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1753\u001b[0m        \u001b[32m0.1514\u001b[0m     +  4.0953\n",
      "      2        \u001b[36m0.1616\u001b[0m        0.1547        4.2524\n",
      "      3        \u001b[36m0.1583\u001b[0m        \u001b[32m0.1509\u001b[0m     +  4.2040\n",
      "      4        \u001b[36m0.1560\u001b[0m        \u001b[32m0.1503\u001b[0m     +  4.1289\n",
      "      5        \u001b[36m0.1542\u001b[0m        \u001b[32m0.1477\u001b[0m     +  4.0640\n",
      "      6        \u001b[36m0.1526\u001b[0m        0.1487        4.1585\n",
      "      7        \u001b[36m0.1515\u001b[0m        \u001b[32m0.1470\u001b[0m     +  4.0953\n",
      "      8        \u001b[36m0.1506\u001b[0m        0.1502        4.1308\n",
      "      9        \u001b[36m0.1493\u001b[0m        0.1494        4.1544\n",
      "     10        \u001b[36m0.1491\u001b[0m        0.1481        4.1146\n",
      "     11        \u001b[36m0.1479\u001b[0m        0.1499        4.1187\n",
      "     12        0.1479        0.1505        4.2340\n",
      "     13        \u001b[36m0.1474\u001b[0m        0.1502        4.0484\n",
      "     14        \u001b[36m0.1468\u001b[0m        0.1480        4.1090\n",
      "     15        \u001b[36m0.1460\u001b[0m        0.1492        4.1161\n",
      "     16        0.1462        \u001b[32m0.1464\u001b[0m     +  4.1179\n",
      "     17        \u001b[36m0.1456\u001b[0m        0.1480        4.0862\n",
      "     18        \u001b[36m0.1450\u001b[0m        0.1472        4.1324\n",
      "     19        0.1451        0.1559        4.0504\n",
      "     20        \u001b[36m0.1448\u001b[0m        0.1506        4.0231\n",
      "     21        \u001b[36m0.1442\u001b[0m        0.1501        4.0158\n",
      "     22        \u001b[36m0.1440\u001b[0m        0.1509        4.2108\n",
      "     23        \u001b[36m0.1437\u001b[0m        0.1534        4.0885\n",
      "     24        \u001b[36m0.1433\u001b[0m        0.1540        4.0968\n",
      "     25        \u001b[36m0.1431\u001b[0m        0.1521        4.0854\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1325\u001b[0m        \u001b[32m0.1160\u001b[0m     +  4.2150\n",
      "      2        \u001b[36m0.1080\u001b[0m        \u001b[32m0.1113\u001b[0m     +  4.1338\n",
      "      3        \u001b[36m0.0922\u001b[0m        \u001b[32m0.1096\u001b[0m     +  4.0590\n",
      "      4        \u001b[36m0.0882\u001b[0m        0.1110        4.1530\n",
      "      5        \u001b[36m0.0862\u001b[0m        0.1101        4.0933\n",
      "      6        \u001b[36m0.0833\u001b[0m        0.1109        4.0371\n",
      "      7        \u001b[36m0.0819\u001b[0m        0.1106        4.0174\n",
      "      8        \u001b[36m0.0818\u001b[0m        0.1118        4.0990\n",
      "      9        \u001b[36m0.0798\u001b[0m        0.1114        4.1012\n",
      "     10        \u001b[36m0.0791\u001b[0m        \u001b[32m0.1078\u001b[0m     +  4.1422\n",
      "     11        \u001b[36m0.0786\u001b[0m        0.1104        4.1622\n",
      "     12        \u001b[36m0.0777\u001b[0m        0.1102        4.1061\n",
      "     13        \u001b[36m0.0768\u001b[0m        0.1103        4.1152\n",
      "     14        \u001b[36m0.0747\u001b[0m        0.1094        4.2103\n",
      "     15        0.0761        0.1138        4.1461\n",
      "     16        \u001b[36m0.0744\u001b[0m        0.1140        4.0718\n",
      "     17        \u001b[36m0.0733\u001b[0m        0.1180        4.1377\n",
      "     18        0.0738        0.1093        4.1387\n",
      "     19        \u001b[36m0.0733\u001b[0m        0.1126        4.1576\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1016\u001b[0m        \u001b[32m1.3946\u001b[0m     +  4.1521\n",
      "      2        \u001b[36m0.0903\u001b[0m        \u001b[32m1.2724\u001b[0m     +  4.1336\n",
      "      3        \u001b[36m0.0876\u001b[0m        1.2728        4.1086\n",
      "      4        \u001b[36m0.0861\u001b[0m        1.3153        4.1654\n",
      "      5        \u001b[36m0.0841\u001b[0m        1.3924        4.1199\n",
      "      6        0.0847        1.5598        4.0842\n",
      "      7        \u001b[36m0.0821\u001b[0m        1.2871        4.1251\n",
      "      8        0.0824        1.4577        4.0982\n",
      "      9        0.0830        1.6859        4.0939\n",
      "     10        \u001b[36m0.0811\u001b[0m        1.4115        4.0695\n",
      "     11        0.0816        1.5884        4.1599\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.1733\u001b[0m        \u001b[32m0.1435\u001b[0m     +  4.0772\n",
      "      2        \u001b[36m0.1621\u001b[0m        \u001b[32m0.1426\u001b[0m     +  4.1007\n",
      "      3        \u001b[36m0.1592\u001b[0m        \u001b[32m0.1403\u001b[0m     +  4.0873\n",
      "      4        \u001b[36m0.1577\u001b[0m        \u001b[32m0.1402\u001b[0m     +  4.1215\n",
      "      5        \u001b[36m0.1565\u001b[0m        \u001b[32m0.1399\u001b[0m     +  4.1222\n",
      "      6        \u001b[36m0.1549\u001b[0m        0.1401        4.1017\n",
      "      7        \u001b[36m0.1540\u001b[0m        0.1401        4.1105\n",
      "      8        \u001b[36m0.1529\u001b[0m        0.1399        4.1057\n",
      "      9        \u001b[36m0.1522\u001b[0m        \u001b[32m0.1397\u001b[0m     +  4.1780\n",
      "     10        \u001b[36m0.1515\u001b[0m        \u001b[32m0.1394\u001b[0m     +  4.1811\n",
      "     11        \u001b[36m0.1513\u001b[0m        0.1410        4.1203\n",
      "     12        \u001b[36m0.1504\u001b[0m        0.1400        4.2257\n",
      "     13        \u001b[36m0.1498\u001b[0m        0.1407        4.1253\n",
      "     14        \u001b[36m0.1493\u001b[0m        0.1424        4.1368\n",
      "     15        \u001b[36m0.1489\u001b[0m        0.1419        4.1304\n",
      "     16        0.1490        0.1413        4.1956\n",
      "     17        \u001b[36m0.1486\u001b[0m        0.1412        4.1645\n",
      "     18        \u001b[36m0.1479\u001b[0m        0.1417        4.0550\n",
      "     19        \u001b[36m0.1475\u001b[0m        0.1416        4.0228\n",
      "Stopping since valid_loss has not improved in the last 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "for cluster in df[split_col].unique():\n",
    "    train_df = train_df_by_cluster[cluster]\n",
    "    train_x = train_df[x_cols].values.astype(np.float32)\n",
    "    train_y = train_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "\n",
    "    if not final_run:\n",
    "        val_df = val_df_by_cluster[cluster]\n",
    "        train_params['train_split'] = predefined_split(Dataset(val_df[x_cols].values.astype(np.float32), val_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)))\n",
    "    else:\n",
    "        train_params['train_split'] = None\n",
    "\n",
    "    callbacks = [EarlyStopping(patience=10, threshold=0.0001, threshold_mode='abs', monitor='valid_loss', lower_is_better=True),\n",
    "            Checkpoint(monitor='valid_loss_best', f_params=f'sales_forecaster_{cluster}.pt', dirname='models/'),\n",
    "            LRScheduler(policy=ReduceLROnPlateau, monitor='train_loss', factor=0.5, patience=5, threshold=0.001, threshold_mode='abs', mode='min', verbose=True)\n",
    "            ]\n",
    "\n",
    "    train_params['callbacks'] = callbacks\n",
    "\n",
    "    net = NeuralNetRegressor(FFNeuralNetwork(**net_params), **train_params)\n",
    "\n",
    "    print(cluster)\n",
    "\n",
    "     \n",
    "    net.fit(train_x, train_y)\n",
    "    net_by_cluster[cluster] = net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Nets from Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in df[split_col].unique():\n",
    "    net = NeuralNetRegressor(FFNeuralNetwork(**net_params), **train_params)\n",
    "    net.initialize()\n",
    "    net.load_params(f_params=f'models/sales_forecaster_{cluster}.pt')\n",
    "    net_by_cluster[cluster] = net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "endogenous_cols = [\n",
    "        'sales', 'onpromotion', 'oil', \n",
    "       'dow_avg_sales', 'dow_rolling_3_sales', 'dow_rolling_7_sales',\n",
    "       'dow_avg_transactions', 'dow_rolling_3_transactions',\n",
    "       'dow_rolling_7_transactions', 'rolling_7_sales', 'rolling_14_sales',\n",
    "       'rolling_7_transactions', 'rolling_14_transactions']\n",
    "\n",
    "exogenous_cols = [\n",
    "    'h_type_nat', 'h_description_nat', 'h_transferred_nat', 'h_type_loc',\n",
    "    'h_description_loc', 'h_transferred_loc', 'month', 'day', 'day_of_week', 'store_nbr'\n",
    "    ]\n",
    "\n",
    "out_cols = ['sales']\n",
    "\n",
    "\n",
    "lstm_net_by_cluster = {}\n",
    "lstm_net_params = {\n",
    "    'input_dim': 512,\n",
    "    'endogenous_dim': len(endogenous_cols)*54,\n",
    "    'endogenous_len': 5,\n",
    "    'exogenous_dim': len(exogenous_cols),\n",
    "    'hidden_dim': 1024,\n",
    "    'out_dim': 54,\n",
    "    'out_seq_len': 15,\n",
    "    'num_layers': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, RMSLE: 0.59281 L1: 2621.91406\n",
      "Epoch 2/1000, RMSLE: 0.59805 L1: 2591.96606\n",
      "Epoch 3/1000, RMSLE: 0.61355 L1: 2627.24707\n",
      "Epoch 4/1000, RMSLE: 0.61980 L1: 2648.24902\n",
      "Epoch 5/1000, RMSLE: 0.63566 L1: 2669.86035\n",
      "Epoch 6/1000, RMSLE: 0.64438 L1: 2688.27637\n",
      "Epoch 7/1000, RMSLE: 0.66854 L1: 2746.78809\n",
      "Epoch 8/1000, RMSLE: 0.68094 L1: 2764.41455\n",
      "Epoch 9/1000, RMSLE: 0.69042 L1: 2781.10596\n",
      "Epoch 10/1000, RMSLE: 0.69891 L1: 2787.39185\n",
      "Epoch 11/1000, RMSLE: 0.69744 L1: 2791.86279\n",
      "Epoch 12/1000, RMSLE: 0.69394 L1: 2789.51074\n",
      "Epoch 13/1000, RMSLE: 0.70647 L1: 2797.06030\n",
      "Epoch 14/1000, RMSLE: 0.69428 L1: 2787.90845\n",
      "Epoch 15/1000, RMSLE: 0.70769 L1: 2804.49365\n",
      "Epoch 16/1000, RMSLE: 0.69218 L1: 2788.97607\n",
      "Epoch 17/1000, RMSLE: 0.71373 L1: 2809.92358\n",
      "Epoch 18/1000, RMSLE: 0.68829 L1: 2788.63428\n",
      "Epoch 19/1000, RMSLE: 0.71235 L1: 2810.70557\n",
      "Epoch 20/1000, RMSLE: 0.68650 L1: 2790.86255\n",
      "Epoch 21/1000, RMSLE: 0.71120 L1: 2808.48950\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 1000\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    train_df = train_df_by_cluster[cluster]\n",
    "    train_dataset = LSTMDataset(train_df, 5, 15, 'date', endogenous_cols, exogenous_cols, out_cols, 'store_nbr')\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=30, shuffle=False)\n",
    "\n",
    "    scaler_y = scaler_y_by_cluster[cluster]\n",
    "\n",
    "    val_df = val_df_by_cluster[cluster]\n",
    "    val_dataset = LSTMDataset(val_df, 5, 15, 'date', endogenous_cols, exogenous_cols, out_cols, 'store_nbr')\n",
    "\n",
    "    model = LSTMNeuralNetwork(**lstm_net_params)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-8)\n",
    "    criterion = nn.L1Loss()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    model.zero_grad()\n",
    "\n",
    "    val = val_dataset[0]\n",
    "    val_endog = torch.tensor(val['endog']).unsqueeze(0).to(device).to(torch.float32)\n",
    "    val_exog = torch.tensor(val['exog']).unsqueeze(0).to(device).to(torch.float32)\n",
    "    val_y = scaler_y.inverse_transform(val['label'].reshape(-1,1).astype(np.float32))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for sample in train_loader:\n",
    "            endog = sample['endog'].to(device).to(torch.float32)\n",
    "            exog = sample['exog'].to(device).to(torch.float32)\n",
    "            y = sample['label'].to(device).to(torch.float32)\n",
    "            optim.zero_grad()\n",
    "            output = model((endog, exog))\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_pred = model((val_endog, val_exog))\n",
    "            val_pred = val_pred.view(-1,1).cpu().detach().numpy()\n",
    "            val_pred = scaler_y.inverse_transform(val_pred)\n",
    "\n",
    "            val_loss1 = rmsle(val_y, val_pred.clip(0))\n",
    "            val_loss2 = np.abs(val_y - val_pred).sum()\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, RMSLE: {val_loss1.item():6.5f} L1: {val_loss2:6.5f}')\n",
    "            model.train()\n",
    "\n",
    "\n",
    "    lstm_net_by_cluster[cluster] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "cluster_rfs = {}\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    train_df = train_df_by_cluster[cluster]\n",
    "\n",
    "    train_x = train_df[x_cols].values.astype(np.float32)\n",
    "    train_y = train_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=4)\n",
    "    rf.fit(train_x, train_y.squeeze())\n",
    "\n",
    "    cluster_rfs[cluster] = rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "cluster_xgb = {}\n",
    "for cluster in df[split_col].unique():\n",
    "    train_x = train_x_by_cluster[cluster]\n",
    "    train_y = train_y_by_cluster[cluster]\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=1000, max_depth=12, learning_rate=0.001, random_state=42, n_jobs=2)\n",
    "    xgb_model.fit(train_x, train_y.squeeze())\n",
    "\n",
    "    cluster_xgb[cluster] = xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_train_preds = []\n",
    "rf_train_preds = []\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    train_df = train_df_by_cluster[cluster]\n",
    "\n",
    "    train_x = train_df[x_cols].values.astype(np.float32)\n",
    "    train_y = train_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "    y_scaler = scaler_y_by_cluster[cluster]\n",
    "\n",
    "    net = net_by_cluster[cluster]\n",
    "    rf = cluster_rfs[cluster]\n",
    "\n",
    "    net_preds = net.predict(train_x)\n",
    "    rf_preds = rf.predict(train_x)\n",
    "\n",
    "    train_df['sales_nn'] = net_preds\n",
    "    train_df['sales_rf'] = rf_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Loss Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF RMSLE: 0.4077625548953881\n",
      "NN RMSLE: 0.39476779103279114\n"
     ]
    }
   ],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_true) - np.log1p(y_pred))))\n",
    "\n",
    "rf_preds = []\n",
    "net_preds = []\n",
    "xgb_preds = []\n",
    "val_y_true = []\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    val_cluster_df = val_df_by_cluster[cluster]\n",
    "    val_x = val_cluster_df[x_cols].values.astype(np.float32)\n",
    "    val_y = val_cluster_df[y_cols].values.reshape(-1, len(y_cols)).astype(np.float32)\n",
    "\n",
    "    rf = cluster_rfs[cluster]\n",
    "    net = net_by_cluster[cluster]\n",
    "\n",
    "    rf_preds.append(scaler_y_by_cluster[cluster].inverse_transform(rf.predict(val_x).reshape(-1, 1)))\n",
    "    net_preds.append(scaler_y_by_cluster[cluster].inverse_transform(net.predict(val_x).reshape(-1, 1)).clip(0))    \n",
    "    #xgb_preds.append(scaler_y_by_cluster[cluster].inverse_transform(cluster_xgb[cluster].predict(val_x).reshape(-1, 1)))\n",
    "    val_y_true.append(scaler_y_by_cluster[cluster].inverse_transform(val_y))\n",
    "\n",
    "    #rf_preds.append(rf.predict(val_x).reshape(-1, 1))\n",
    "    #net_preds.append(net.predict(val_x).reshape(-1, 1).clip(0) )\n",
    "    #val_y_true.append(val_y)   \n",
    "\n",
    "\n",
    "rf_preds = np.concatenate(rf_preds)\n",
    "net_preds = np.concatenate(net_preds)\n",
    "#xgb_preds = np.concatenate(xgb_preds)\n",
    "val_y_true = np.concatenate(val_y_true)\n",
    "\n",
    "print(f'RF RMSLE: {rmsle(val_y_true, rf_preds)}')\n",
    "#print(f'XGB RMSLE: {rmsle(val_y_true, xgb_preds)}')\n",
    "print(f'NN RMSLE: {rmsle(val_y_true, net_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store_nbr",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "family",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "onpromotion",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "city",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "state",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store_type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "oil",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "h_type_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_description_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_transferred_nat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_type_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_description_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h_transferred_loc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_of_week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dow_avg_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_1_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_3_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_7_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_1_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_7_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_14_sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_avg_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_1_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_3_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dow_rolling_7_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_1_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_7_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_14_transactions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_payday",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "is_earth_quake",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "is_weekday",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_weekend",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5c7ac538-06e4-4de1-9df9-70e2a7683830",
       "rows": [
        [
         "3000888",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "3.547008547008547",
         "4.0",
         "4.333333333333333",
         "3.4285714285714284",
         "4.0",
         "4.0",
         "2.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0",
         "False",
         "False",
         "1",
         "0"
        ],
        [
         "3000889",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0",
         "False",
         "False",
         "1",
         "0"
        ],
        [
         "3000890",
         "1",
         "2",
         "2",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "2.6367521367521367",
         "2.0",
         "2.6666666666666665",
         "3.857142857142857",
         "2.0",
         "2.0",
         "3.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0",
         "False",
         "False",
         "1",
         "0"
        ],
        [
         "3000891",
         "1",
         "3",
         "20",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "1861.82905982906",
         "2645.0",
         "2418.6666666666665",
         "2456.1428571428573",
         "2418.0",
         "2645.0",
         "2242.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0",
         "False",
         "False",
         "1",
         "0"
        ],
        [
         "3000892",
         "1",
         "4",
         "0",
         "0",
         "0",
         "0",
         "13",
         "46.8",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "2017",
         "8",
         "16",
         "2",
         "0.1709401709401709",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1861.739316239316",
         "1892.0",
         "1864.0",
         "1888.857142857143",
         "1766.0",
         "1892.0",
         "1903.0",
         "False",
         "False",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 36,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>store_type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>oil</th>\n",
       "      <th>h_type_nat</th>\n",
       "      <th>h_description_nat</th>\n",
       "      <th>...</th>\n",
       "      <th>dow_rolling_1_transactions</th>\n",
       "      <th>dow_rolling_3_transactions</th>\n",
       "      <th>dow_rolling_7_transactions</th>\n",
       "      <th>prev_1_transactions</th>\n",
       "      <th>prev_7_transactions</th>\n",
       "      <th>prev_14_transactions</th>\n",
       "      <th>is_payday</th>\n",
       "      <th>is_earth_quake</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000888</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000890</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000891</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000892</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1888.857143</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         store_nbr  family  onpromotion  city  state  store_type  cluster  \\\n",
       "id                                                                          \n",
       "3000888          1       0            0     0      0           0       13   \n",
       "3000889          1       1            0     0      0           0       13   \n",
       "3000890          1       2            2     0      0           0       13   \n",
       "3000891          1       3           20     0      0           0       13   \n",
       "3000892          1       4            0     0      0           0       13   \n",
       "\n",
       "          oil  h_type_nat  h_description_nat  ...  dow_rolling_1_transactions  \\\n",
       "id                                            ...                               \n",
       "3000888  46.8           0                  0  ...                      1892.0   \n",
       "3000889  46.8           0                  0  ...                      1892.0   \n",
       "3000890  46.8           0                  0  ...                      1892.0   \n",
       "3000891  46.8           0                  0  ...                      1892.0   \n",
       "3000892  46.8           0                  0  ...                      1892.0   \n",
       "\n",
       "         dow_rolling_3_transactions  dow_rolling_7_transactions  \\\n",
       "id                                                                \n",
       "3000888                      1864.0                 1888.857143   \n",
       "3000889                      1864.0                 1888.857143   \n",
       "3000890                      1864.0                 1888.857143   \n",
       "3000891                      1864.0                 1888.857143   \n",
       "3000892                      1864.0                 1888.857143   \n",
       "\n",
       "         prev_1_transactions  prev_7_transactions  prev_14_transactions  \\\n",
       "id                                                                        \n",
       "3000888               1766.0               1892.0                1903.0   \n",
       "3000889               1766.0               1892.0                1903.0   \n",
       "3000890               1766.0               1892.0                1903.0   \n",
       "3000891               1766.0               1892.0                1903.0   \n",
       "3000892               1766.0               1892.0                1903.0   \n",
       "\n",
       "         is_payday  is_earth_quake  is_weekday  is_weekend  \n",
       "id                                                          \n",
       "3000888      False           False           1           0  \n",
       "3000889      False           False           1           0  \n",
       "3000890      False           False           1           0  \n",
       "3000891      False           False           1           0  \n",
       "3000892      False           False           1           0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5a74517e-f7ff-4235-8817-4eb5bfd65c56",
       "rows": [
        [
         "3000888",
         "4.41528844833374"
        ],
        [
         "3000889",
         "0.00011973446817137301"
        ],
        [
         "3000890",
         "4.730281829833984"
        ],
        [
         "3000891",
         "2429.969482421875"
        ],
        [
         "3000892",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000888</th>\n",
       "      <td>4.415288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000889</th>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000890</th>\n",
       "      <td>4.730282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000891</th>\n",
       "      <td>2429.969482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000892</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sales\n",
       "id                  \n",
       "3000888     4.415288\n",
       "3000889     0.000120\n",
       "3000890     4.730282\n",
       "3000891  2429.969482\n",
       "3000892     0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "131a388e-ccef-408e-9a96-2ad522bb4925",
       "rows": [
        [
         "3000888",
         "4.0387003133873804"
        ],
        [
         "3000889",
         "0.004688116300357897"
        ],
        [
         "3000890",
         "4.437217031905455"
        ],
        [
         "3000891",
         "2406.571370813594"
        ],
        [
         "3000892",
         "0.16604992299730176"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000888</th>\n",
       "      <td>4.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000889</th>\n",
       "      <td>0.004688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000890</th>\n",
       "      <td>4.437217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000891</th>\n",
       "      <td>2406.571371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000892</th>\n",
       "      <td>0.166050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sales\n",
       "id                  \n",
       "3000888     4.038700\n",
       "3000889     0.004688\n",
       "3000890     4.437217\n",
       "3000891  2406.571371\n",
       "3000892     0.166050"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_dir, 'test_data.csv'), index_col=0)\n",
    "display(test_df.head())\n",
    "\n",
    "test_x_by_cluster = {}\n",
    "test_id_by_cluster = {}\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    test_cluster_min_max_scaler, test_cluster_normalize_scaler = scaler_x_by_cluster[cluster]\n",
    "    test_cluster_y_scaler = scaler_y_by_cluster[cluster]\n",
    "\n",
    "    test_cluster_x_df = test_df[test_df[split_col] == cluster]\n",
    "    test_cluster_x_df = test_cluster_x_df.drop(columns=split_col)\n",
    "\n",
    "    test_cluster_x_min_max = test_cluster_x_df[min_max_cols].values.astype(np.float32)\n",
    "    test_cluster_x_normalize = test_cluster_x_df[normalize_cols].values.astype(np.float32)\n",
    "\n",
    "    test_cluster_x_min_max = test_cluster_min_max_scaler.transform(test_cluster_x_min_max)\n",
    "    test_cluster_x_normalize = test_cluster_normalize_scaler.transform(test_cluster_x_normalize)\n",
    "    #test_cluster_x_normalize = test_cluster_x_normalize\n",
    "\n",
    "    test_x_by_cluster[cluster] = np.concatenate([test_cluster_x_min_max, test_cluster_x_normalize], axis=1)\n",
    "    test_id_by_cluster[cluster] = test_cluster_x_df.index\n",
    "\n",
    "\n",
    "test_preds_dfs = []\n",
    "\n",
    "for cluster in df[split_col].unique():\n",
    "    test_x = test_x_by_cluster[cluster]\n",
    "    id = test_id_by_cluster[cluster]\n",
    "    rf = cluster_rfs[cluster]\n",
    "    net = net_by_cluster[cluster]\n",
    "\n",
    "    pred_rf = scaler_y_by_cluster[cluster].inverse_transform(rf.predict(test_x).reshape(-1, 1))\n",
    "    #pred_xgb = scaler_y_by_cluster[cluster].inverse_transform(cluster_xgb[cluster].predict(test_x).reshape(-1, 1))\n",
    "    pred_nn = scaler_y_by_cluster[cluster].inverse_transform(net_by_cluster[cluster].predict(test_x).reshape(-1, 1)).clip(0)\n",
    "\n",
    "    #pred_rf = rf.predict(test_x).reshape(-1, 1)\n",
    "    #pred_nn = net.predict(test_x).reshape(-1, 1).clip(0)\n",
    "\n",
    "    \n",
    "    #cluster_df = pd.DataFrame(np.concatenate([pred_nn], axis=1), index=id, columns=['sales_nn'])\n",
    "    cluster_df = pd.DataFrame(np.concatenate([pred_rf, pred_nn], axis=1), index=id, columns=['sales_rf', 'sales_nn'])\n",
    "\n",
    "    test_preds_dfs.append(cluster_df)\n",
    "\n",
    "test_preds_df = pd.concat(test_preds_dfs)\n",
    "\n",
    "test_df = test_df.merge(test_preds_df, on='id', how='left')\n",
    "\n",
    "sub_df_nn = test_df[['sales_nn']]\n",
    "sub_df_rf = test_df[['sales_rf']]\n",
    "#sub_df_xgb = test_df[['sales_xgb']]\n",
    "\n",
    "sub_df_rf = sub_df_rf.rename(columns={'sales_rf': 'sales'})\n",
    "#sub_df_xgb = sub_df_xgb.rename(columns={'sales_xgb': 'sales'})\n",
    "sub_df_nn = sub_df_nn.rename(columns={'sales_nn': 'sales'})\n",
    "\n",
    "\n",
    "display(sub_df_nn.head())\n",
    "display(sub_df_rf.head())\n",
    "#display(sub_df_xgb.head())\n",
    "\n",
    "sub_df_nn.to_csv('data/submission_nn.csv')\n",
    "#sub_df_xgb.to_csv('data/submission_xgb.csv')\n",
    "sub_df_rf.to_csv('data/submission_rf.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
